<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Hybrid Debye-Lorentz Model Fitter</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.32.0.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        @media (max-width: 1024px) {
          #split-root {
            flex-direction: column;
          }
          #dragbar { display:none; }
          #pane-left { width: 100% !important; border-right: none; border-bottom: 1px solid rgb(229 231 235); }
        }
        #kpi-wrapper { transition: box-shadow .15s; }
        #kpi-wrapper:hover { box-shadow: 0 4px 12px rgb(0 0 0 / .15); }
        .spinner {
            border-top-color: #3498db;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        .btn-disabled {
            background-color: #9ca3af;
            cursor: not-allowed;
            opacity: 0.7;
        }
        /* Style for parameter sliders */
        input[type=range] {
            -webkit-appearance: none;
            appearance: none;
            width: 100%;
            height: 6px;
            background: #d1d5db;
            border-radius: 3px;
            outline: none;
            opacity: 0.7;
            transition: opacity .2s;
        }
        input[type=range]:hover {
            opacity: 1;
        }
        input[type=range]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 16px;
            height: 16px;
            background: #3b82f6;
            cursor: pointer;
            border-radius: 50%;
        }
        input[type=range]::-moz-range-thumb {
            width: 16px;
            height: 16px;
            background: #3b82f6;
            cursor: pointer;
            border-radius: 50%;
        }
        .param-input {
            width: 80px;
            padding: 2px 4px;
            border: 1px solid #d1d5db;
            border-radius: 4px;
            font-size: 0.875rem;
        }
    </style>
</head>
<body class="bg-gray-100 text-gray-800">

    <div class="container mx-auto p-4 md:p-8 max-w-7xl">
        <header class="text-center mb-8">
            <h1 class="text-3xl md:text-4xl font-bold text-gray-900">Interactive Hybrid Debye-Lorentz Model Fitter</h1>
            <p class="mt-2 text-lg text-gray-600">Upload your dielectric spectroscopy data (CSV) to fit it to the Hybrid Debye-Lorentz model with N terms.</p>
        </header>

        <div class="bg-white rounded-xl shadow-lg p-6 md:p-8">
            <!-- Controls Section -->
            <div class="grid grid-cols-1 md:grid-cols-2 gap-6 items-center mb-6">
                <div>
                    <label for="file-upload" class="block text-sm font-medium text-gray-700 mb-2">
                        Upload CSV File
                    </label>
                    <div class="flex items-center space-x-4">
                        <input type="file" id="file-upload" accept=".csv" class="block w-full text-sm text-gray-500
                            file:mr-4 file:py-2 file:px-4
                            file:rounded-lg file:border-0
                            file:text-sm file:font-semibold
                            file:bg-blue-50 file:text-blue-700
                            hover:file:bg-blue-100
                        ">
                    </div>
                     <p class="text-xs text-gray-500 mt-2">Expected columns: Frequency (GHz), Dk, Df</p>
                </div>
                <div class="space-y-4">
                    <div>
                        <label for="n-terms" class="block text-sm font-medium text-gray-700">Number of Terms (N)</label>
                        <select id="n-terms" class="mt-1 block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-blue-500 focus:border-blue-500 sm:text-sm rounded-md">
                            <option value="1">1 term</option>
                            <option value="2" selected>2 terms</option>
                            <option value="3">3 terms</option>
                            <option value="4">4 terms</option>
                            <option value="5">5 terms</option>
                        </select>
                    </div>
                    <div>
                        <label for="fit-method" class="block text-sm font-medium text-gray-700">Optimization Method</label>
                        <select id="fit-method" class="mt-1 block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-blue-500 focus:border-blue-500 sm:text-sm rounded-md">
                            <option value="least_squares" selected>least_squares (Default)</option>
                            <option value="nelder">nelder</option>
                            <option value="lbfgsb">lbfgsb</option>
                        </select>
                    </div>
                    <button id="run-button" class="w-full bg-blue-600 text-white font-bold py-3 px-6 rounded-lg shadow-md hover:bg-blue-700 transition-colors duration-300 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50">
                        Run Analysis
                    </button>
                </div>
            </div>

            <!-- Status and Output Section -->
            <div id="status" class="text-center my-4 p-4 bg-gray-50 rounded-lg hidden">
                <div class="flex items-center justify-center">
                    <div class="spinner w-6 h-6 rounded-full border-4 border-gray-300"></div>
                    <p id="status-message" class="ml-4 text-gray-700 font-medium"></p>
                </div>
            </div>

            <div id="output" class="hidden mt-8 h-[calc(100vh-14rem)]">

              <!-- Split container -->
              <div id="split-root" class="flex h-full w-full overflow-hidden">

                <!-- LEFT PANE – plots -->
                <div id="pane-left"
                     class="relative w-[66%] min-w-[360px] flex-shrink-0 overflow-auto border-r">
                  <div id="plot-output" class="h-full"></div>

                  <!-- KPI overlay -->
                  <div id="kpi-wrapper"
                       class="fixed top-20 right-8 w-72 space-y-3 z-40 cursor-move select-none">
                    <div id="fit-quality-indicator" class="mb-4 p-3 rounded-lg hidden">
                      <div class="flex items-center justify-between">
                        <span class="text-sm font-medium">Fit Quality:</span>
                        <span id="fit-quality-score" class="text-lg font-bold"></span>
                      </div>
                      <div class="w-full bg-gray-200 rounded-full h-2 mt-2">
                        <div id="fit-quality-bar" class="h-2 rounded-full transition-all duration-300"></div>
                      </div>
                    </div>
                    <div id="radar-chart-container" class="mb-4 border border-gray-200 rounded-lg bg-gray-50 hidden">
                      <div class="flex items-center justify-between p-3 border-b border-gray-200 cursor-pointer" id="radar-toggle">
                        <h4 class="text-sm font-semibold text-gray-700">Metric Breakdown</h4>
                        <svg id="radar-chevron" class="w-4 h-4 transform transition-transform text-gray-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"></path>
                        </svg>
                      </div>
                      <div id="radar-content" class="p-4">
                        <div id="radar-chart" class="w-full overflow-hidden" style="height: 320px; max-width: 100%;"></div>
                      </div>
                    </div>
                  </div>
                </div>

                <!-- DRAG BAR -->
                <div id="dragbar"
                     class="w-1 bg-gray-300 cursor-col-resize hover:bg-gray-400"></div>

                <!-- RIGHT PANE – parameters & scoring -->
                <div id="pane-right" class="flex-1 overflow-auto p-6 space-y-6">

                  <!-- Buttons -->
                  <div class="flex justify-end space-x-2">
                    <button id="reset-button"
                            class="bg-gray-200 hover:bg-gray-300 px-3 py-1 rounded text-sm">
                      Reset
                    </button>
                    <button id="download-button"
                            class="bg-blue-600 hover:bg-blue-700 text-white px-3 py-1 rounded text-sm">
                      Download
                    </button>
                  </div>

                  <!-- Parameter sliders injected here -->
                  <h3 class="text-xl font-bold">Adjust Parameters</h3>
                  <div id="parameters-display" class="space-y-6"></div>

                  <!-- Collapsible scoring -->
                  <details id="scoring-prefs" class="hidden">
                    <summary class="font-semibold cursor-pointer">
                      Scoring priorities
                    </summary>
                    <div id="scoring-sliders" class="mt-4 space-y-4">
                      <div class="slider-group">
                        <label class="flex items-center justify-between text-xs text-gray-600">
                          <span>Uniform Fit Across Bands</span>
                          <span id="weight-regional_fit-value" class="font-mono">4.0</span>
                        </label>
                        <input type="range" id="weight-regional_fit" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer" 
                               min="0" max="5" step="0.5" value="4" />
                      </div>
                      <div class="slider-group">
                        <label class="flex items-center justify-between text-xs text-gray-600">
                          <span>Low RMS in Dk</span>
                          <span id="weight-rms_real-value" class="font-mono">3.0</span>
                        </label>
                        <input type="range" id="weight-rms_real" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer" 
                               min="0" max="5" step="0.5" value="3" />
                      </div>
                      <div class="slider-group">
                        <label class="flex items-center justify-between text-xs text-gray-600">
                          <span>Low RMS in Df</span>
                          <span id="weight-rms_imag-value" class="font-mono">3.0</span>
                        </label>
                        <input type="range" id="weight-rms_imag" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer" 
                               min="0" max="5" step="0.5" value="3" />
                      </div>
                      <div class="slider-group">
                        <label class="flex items-center justify-between text-xs text-gray-600">
                          <span>Chi-Square Fit</span>
                          <span id="weight-reduced_chi_square-value" class="font-mono">2.0</span>
                        </label>
                        <input type="range" id="weight-reduced_chi_square" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer" 
                               min="0" max="5" step="0.5" value="2" />
                      </div>
                      <div class="slider-group">
                        <label class="flex items-center justify-between text-xs text-gray-600">
                          <span>Model Simplicity (BIC)</span>
                          <span id="weight-bic-value" class="font-mono">2.0</span>
                        </label>
                        <input type="range" id="weight-bic" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer" 
                               min="0" max="5" step="0.5" value="2" />
                      </div>
                    </div>
                    <button id="apply-scoring-prefs"
                            class="mt-4 w-full bg-blue-600 hover:bg-blue-700 text-white py-2 text-sm rounded">
                      Apply changes
                    </button>
                  </details>

                </div>
              </div>

              <!-- Report Display -->
              <div class="mt-8">
                <h2 class="text-2xl font-bold mb-4 text-gray-800">Fit Report</h2>
                <div class="bg-gray-900 text-white font-mono text-sm p-6 rounded-lg overflow-x-auto">
                  <pre id="report-output"></pre>
                </div>
              </div>
            </div>
             <!-- Error Display -->
            <div id="error-box" class="hidden mt-6 p-4 bg-red-100 border border-red-400 text-red-700 rounded-lg">
                <h3 class="font-bold">An Error Occurred</h3>
                <p id="error-message"></p>
            </div>
        </div>
        <footer class="text-center mt-8 text-sm text-gray-500">
            <p>Powered by Pyodide, lmfit, and plotly</p>
            <div class="border-t border-gray-300 pt-2 mt-2">
            <p class="font-semibold text-gray-700">Citation</p>
            <p class="italic">Meddeb, B., & Meddeb, A. (2025). QuickFitter: Interactive Dielectric Data Fitting Tool.
            <br>Available at: <a href="https://github.com/bmeddeb/QuickFitter" class="text-blue-600 hover:underline">https://github.com/bmeddeb/QuickFitter</a></p>
        </div>
        </footer>
    </div>

    <script type="text/javascript">
        // DOM Elements
        const fileUpload = document.getElementById('file-upload');
        const runButton = document.getElementById('run-button');
        const resetButton = document.getElementById('reset-button');
        const downloadButton = document.getElementById('download-button');
        const nTermsSelect = document.getElementById('n-terms');
        const fitMethodSelect = document.getElementById('fit-method');
        const statusDiv = document.getElementById('status');
        const statusMessage = document.getElementById('status-message');
        const outputDiv = document.getElementById('output');
        const plotOutput = document.getElementById('plot-output');
        const reportOutput = document.getElementById('report-output');
        const errorBox = document.getElementById('error-box');
        const errorMessage = document.getElementById('error-message');
        const parametersDisplay = document.getElementById('parameters-display');

        // Global State
        let pyodide = null;
        let fileContent = null;
        let isPyodideReady = false;
        let currentData = null;
        let originalFilename = '';
        let paramControls = {};
        let originalParams = null;

        // Python Script
        const pythonScript = `
import sys
import io
import json
from datetime import datetime
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.io as pio
from lmfit import Minimizer, Parameters, fit_report
import math
import logging
from typing import Dict, Tuple, Any, List, Optional
from dataclasses import dataclass, field

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Fit Evaluator Classes for Hybrid Model
@dataclass
class MetricResult:
    """Stores the evaluation result for a single metric."""
    name: str
    score: float
    category: str
    value: float
    suggestion: str | None = None
    details: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ReportEvaluation:
    """Stores the full evaluation for a report."""
    metrics: Dict[str, MetricResult]
    overall: MetricResult
    suggestions: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)

    def to_markdown(self) -> str:
        """Return the evaluation as a markdown-formatted table."""
        headers = ["Metric", "Score", "Category", "Value", "Suggestion"]
        lines = ["| " + " | ".join(headers) + " |",
                 "| " + " | ".join(["---"]*len(headers)) + " |"]
        for m in self.metrics.values():
            suggestion = m.suggestion or ""
            lines.append(f"| {m.name} | {m.score} | {m.category} | {m.value:.4g} | {suggestion} |")
        lines.append(
            f"| **Overall** | {self.overall.score} | {self.overall.category} | {self.overall.value} |  |"
        )
        if self.warnings:
            lines.append("\\n**Warnings:**")
            for warning in self.warnings:
                lines.append(f"- {warning}")
        return "\\n".join(lines)

    def to_dict(self) -> Dict[str, Any]:
        """Convert evaluation to dictionary format."""
        return {
            'overall_score': self.overall.score,
            'overall_category': self.overall.category,
            'metrics': {
                k: {
                    'score': v.score,
                    'category': v.category,
                    'value': v.value,
                    'suggestion': v.suggestion,
                    'details': v.details
                }
                for k, v in self.metrics.items()
            },
            'suggestions': self.suggestions,
            'warnings': self.warnings,
            'markdown_table': self.to_markdown()
        }

class HybridModelEvaluator:
    """
    Evaluates the quality of a Hybrid Debye-Lorentz fit report.
    """
    # --- Consolidated, noise-adaptive thresholds ---
    DEFAULT_THRESHOLDS = {
        # name : (mult_godly, mult_excellent, mult_good, suggestion)
        "reduced_chi_square": (1.0, 5.0, 10.0, "Check model overfitting or missing physics."),
        "rms_real":           (1.0, 2.0, 5.0, "Large RMS in Dk—check model adequacy."),
        "rms_imag":           (1.0, 2.0, 5.0, "Large RMS in Df—adjust parameters."),
        "mean_residual":      (1.0, 2.0, 5.0, "Systematic bias detected."),
    }

    HYBRID_WEIGHTS: Dict[str, float] = {
        'dpv': 1.0,
        'reduced_chi_square': 2.0,
        'rms_real': 3.0,
        'rms_imag': 3.0,
        'mean_residual': 2.0,
        'regional_fit': 4.0,
        'tau_separation': 2.0,
        'min_contribution': 3.0,
        'max_contribution': 2.0,
        'correlation': 4.0,
        'like_param_correlation': 2.0,
        'complexity_penalty': 2.0,
        'bic': 2.0
    }

    def __init__(self, weights=None, data_props=None):
        self.data_props = data_props or {}
        self.base_weights = weights or self.HYBRID_WEIGHTS
        self.weights = self._adapt_weights(self.base_weights, self.data_props)
    
    def _adapt_weights(self, base_weights: Dict[str, float], data_props: Dict[str, Any]) -> Dict[str, float]:
        """
        Dynamically adjust metric weights based on data properties.
        
        Args:
            base_weights: The base weights to start from
            data_props: Dictionary containing:
                - dpv: data points per variable
                - freq_span: frequency span in decades (log10(f_max/f_min))
                - sigma_real: noise level in real part
                - sigma_imag: noise level in imaginary part
        
        Returns:
            Adapted weights dictionary
        """
        weights = base_weights.copy()
        
        # If UI weights exist, use them as priority and only apply minimal data adaptations
        if hasattr(self, 'ui_weights') and self.ui_weights:
            # Start with UI weights
            for weight_name, weight_value in self.ui_weights.items():
                if weight_name in weights:
                    weights[weight_name] = weight_value
            
            # Apply only critical data-driven adjustments (more conservative)
            # Only apply dpv boost for very low data scenarios
            if data_props.get('dpv', float('inf')) < 5:  # More restrictive threshold
                weights['dpv'] = weights.get('dpv', 1.0) * 1.2  # Smaller multiplier
                
        else:
            # Full data-driven adaptation when no UI weights are set
            # Emphasize dpv metric for low data-point scenarios
            if data_props.get('dpv', float('inf')) < 10:
                weights['dpv'] = weights.get('dpv', 1.0) * 1.5
                
            # Emphasize regional fit for ultra-broadband data (>3 decades)
            if data_props.get('freq_span', 0) > 3:
                weights['regional_fit'] = weights.get('regional_fit', 4.0) * 1.2
                
            # Down-weight rms_imag if real part is much noisier
            if data_props.get('sigma_real', 1) / data_props.get('sigma_imag', 1) > 2:
                weights['rms_imag'] = weights.get('rms_imag', 3.0) * 0.8
                
        return weights

    @classmethod
    def from_json_report(cls, json_data: Dict[str, Any]) -> Dict[str, Any]:
        """Convert JSON report format to evaluator format."""
        fit_stats = json_data.get('fit_statistics', {})
        residuals = json_data.get('residual_analysis', {})
        params = json_data.get('parameters', {})
        n_terms = json_data.get('n_terms', 1)

        # Extract correlation matrix
        corr_matrix = json_data.get('correlation_matrix', [])
        correlations = {}
        if corr_matrix and isinstance(corr_matrix, list):
            param_names = ['eps_inf']
            for i in range(n_terms):
                param_names.extend([f'A{i+1}', f'tau{i+1}', f'alpha{i+1}', f'gamma{i+1}', f'beta{i+1}'])

            try:
                for i in range(len(corr_matrix)):
                    for j in range(i+1, len(corr_matrix[0])):
                        if abs(corr_matrix[i][j]) > 0.1:
                            if i < len(param_names) and j < len(param_names):
                                correlations[(param_names[i], param_names[j])] = corr_matrix[i][j]
            except (IndexError, TypeError) as e:
                logger.warning(f"Error parsing correlation matrix: {e}")

        return {
            'n_data_points': fit_stats.get('n_data_points', 0),
            'n_variables': fit_stats.get('n_variables', 4),
            'chi_square': fit_stats.get('chi_square', 0),
            'reduced_chi_square': fit_stats.get('reduced_chi_square', 0),
            'rms_real': residuals.get('real_part', {}).get('rms', 0),
            'rms_imag': residuals.get('loss_tangent', {}).get('rms', 0),  # Now using loss tangent
            'mean_real': residuals.get('real_part', {}).get('mean', 0),
            'mean_imag': residuals.get('loss_tangent', {}).get('mean', 0),  # Now using loss tangent
            'correlations': correlations,
            'params': params,
            'n_terms': n_terms,
            'information_criteria': json_data.get('information_criteria', {})
        }

    def _validate_report(self, report: Dict[str, Any]) -> None:
        """Validate report data types and values."""
        try:
            n_data = int(report['n_data_points'])
            n_vars = int(report['n_variables'])
            n_terms = int(report['n_terms'])

            if n_vars <= 0:
                raise ValueError("n_variables must be positive")
            if n_data <= n_vars:
                raise ValueError("n_data_points must exceed n_variables")
            if n_terms < 1 or n_terms > 5:
                raise ValueError("n_terms must be between 1 and 5")

            # Check parameter bounds
            params = report['params']
            if params['eps_inf'] <= 0:
                raise ValueError("eps_inf must be positive")

            for i in range(n_terms):
                if params[f'A{i+1}'] < 0:
                    raise ValueError(f"A{i+1} must be non-negative")
                if params[f'tau{i+1}'] <= 0:
                    raise ValueError(f"tau{i+1} must be positive")
                if params[f'alpha{i+1}'] <= 0 or params[f'alpha{i+1}'] > 1:
                    raise ValueError(f"alpha{i+1} must be in (0,1]")
                if params[f'gamma{i+1}'] < 0:
                    raise ValueError(f"gamma{i+1} must be non-negative")
                if params[f'beta{i+1}'] < 0 or params[f'beta{i+1}'] > 1:
                    raise ValueError(f"beta{i+1} must be in [0,1]")

        except (TypeError, ValueError, KeyError) as e:
            raise ValueError(f"Invalid report data: {e}")

    def _validate_hybrid_model(self, params: Dict[str, float], n_terms: int) -> List[str]:
        """Model-specific warnings for Hybrid Debye-Lorentz."""
        warnings = []

        # Check if n_terms is high
        if n_terms > 3:
            warnings.append(f"Using {n_terms} terms - consider if model complexity is justified")

        # Check tau ordering
        taus = [params[f'tau{i+1}'] for i in range(n_terms)]
        sorted_taus = sorted(taus)
        if taus != sorted_taus:
            warnings.append("Tau values not in monotonic order - consider reordering terms")

        # Check tau separation
        for i in range(len(sorted_taus)-1):
            ratio = sorted_taus[i+1] / sorted_taus[i]
            if ratio < 2:
                warnings.append(f"Terms with tau ~{sorted_taus[i]:.2e} and ~{sorted_taus[i+1]:.2e} overlap significantly")

        # Check contributions
        A_vals = [params[f'A{i+1}'] for i in range(n_terms)]
        total_A = sum(A_vals)
        if total_A > 0:
            contributions = [A/total_A for A in A_vals]
            for i, contrib in enumerate(contributions):
                if contrib < 0.01:
                    warnings.append(f"Term {i+1} contributes <1% - consider removing")
                elif contrib > 0.95:
                    warnings.append(f"Term {i+1} dominates (>95%) - other terms may be superfluous")

        # Check alpha/gamma values
        for i in range(n_terms):
            alpha = params[f'alpha{i+1}']
            gamma = params[f'gamma{i+1}']

            if alpha < 0.3:
                warnings.append(f"Term {i+1}: alpha={alpha:.2f} very low (pure Debye-like)")
            elif alpha > 0.95:
                warnings.append(f"Term {i+1}: alpha={alpha:.2f} very high (check causality)")

            if gamma > 2.0:
                warnings.append(f"Term {i+1}: gamma={gamma:.2f} very high (overdamped)")
            elif gamma < 0.1:
                warnings.append(f"Term {i+1}: gamma={gamma:.2f} very low (underdamped)")

        return warnings

    def _evaluate_scalar(self, value: float, thresholds: Tuple[float, float, float]) -> Tuple[int, str]:
        """Evaluates metrics where smaller values are better."""
        godly_max, excellent_max, good_max = thresholds
        if value < godly_max:
            return 100, "Godly"
        elif value < excellent_max:
            return 80, "Excellent"
        elif value < good_max:
            return 60, "Good"
        return 30, "Poor"

    def _evaluate_inverse_scalar(self, value: float, thresholds: Tuple[float, float, float]) -> Tuple[int, str]:
        """Evaluates metrics where larger values are better."""
        poor_min, good_min, excellent_min = thresholds
        if value >= excellent_min:
            return 100, "Godly"
        elif value >= good_min:
            return 80, "Excellent"
        elif value >= poor_min:
            return 60, "Good"
        return 30, "Poor"

    def _evaluate_correlation(self, corr_value: float) -> Tuple[int, str, str | None]:
        """Evaluates correlation, returning score, category, and suggestion."""
        abs_corr = abs(corr_value)
        if abs_corr < 0.50:
            return 100, "Low", None
        elif abs_corr < 0.80:
            return 80, "Moderate", None
        elif abs_corr < 0.95:
            return 60, "High", "Consider fixing one parameter"
        return 30, "Very High", "Parameters are redundant"

    def _evaluate_like_parameter_correlations(self, correlations: Dict, n_terms: int) -> Tuple[float, List[str]]:
        """Evaluate correlations between like parameters (tau1 vs tau2, etc)."""
        like_param_corrs = []
        warnings = []

        # Check correlations between same parameter types
        param_types = ['A', 'tau', 'alpha', 'gamma', 'beta']
        for ptype in param_types:
            for i in range(n_terms):
                for j in range(i+1, n_terms):
                    key1 = f'{ptype}{i+1}'
                    key2 = f'{ptype}{j+1}'
                    # Check both orderings
                    if (key1, key2) in correlations:
                        corr = correlations[(key1, key2)]
                    elif (key2, key1) in correlations:
                        corr = correlations[(key2, key1)]
                    else:
                        continue

                    like_param_corrs.append(abs(corr))
                    if abs(corr) > 0.9:
                        warnings.append(f"{key1} and {key2} highly correlated ({corr:.2f})")

        # Calculate score based on worst correlation
        if like_param_corrs:
            worst_corr = max(like_param_corrs)
            score, _, _ = self._evaluate_correlation(worst_corr)
        else:
            score = 100

        return score, warnings

    def _calculate_complexity_penalty(self, n_terms: int, n_warnings: int) -> float:
        """Calculate a penalty score based on model complexity."""
        # Base penalty for number of terms
        term_penalty = 0
        if n_terms > 3:
            term_penalty = (n_terms - 3) * 10  # -10 points per extra term above 3

        # Warning penalty
        warning_penalty = min(n_warnings * 5, 30)  # -5 points per warning, max -30

        # Total penalty score (100 = no penalty, lower = more penalty)
        penalty_score = max(100 - term_penalty - warning_penalty, 30)

        return penalty_score

    def _validate_frequency_range(self, params: Dict[str, float], n_terms: int, f_ghz_range: Tuple[float, float]) -> List[str]:
        """Check if resonance frequencies are within or near the measurement range."""
        warnings = []
        f_min, f_max = f_ghz_range

        for i in range(n_terms):
            tau = params[f'tau{i+1}']
            f0 = 1 / (2 * np.pi * tau) / 1e9  # Resonance frequency in GHz

            if f0 < f_min * 0.1:  # More than 10x below minimum frequency
                warnings.append(f"Term {i+1} resonance ({f0:.3f} GHz) is far below measurement range ({f_min}-{f_max} GHz)")
            elif f0 > f_max * 10:  # More than 10x above maximum frequency
                warnings.append(f"Term {i+1} resonance ({f0:.3f} GHz) is far above measurement range ({f_min}-{f_max} GHz)")

        return warnings

    def _evaluate_systematic_residuals(self, residuals_real: List[float], residuals_imag: List[float],
                                     f_ghz: List[float]) -> Tuple[float, List[str]]:
        """Check for systematic errors in different frequency regions."""
        warnings = []
        
        f = np.array(f_ghz)
        logf = np.log10(f)
        log_min, log_max = logf.min(), logf.max()
        
        # Breakpoints dividing log-space into thirds
        f_break1 = 10**(log_min + (log_max - log_min)/3)
        f_break2 = 10**(log_min + 2*(log_max - log_min)/3)

        regions = {
            'low':  f <= f_break1,
            'mid':  (f > f_break1) & (f <= f_break2),
            'high': f > f_break2
        }

        max_regional_error = 0

        for region_name, mask in regions.items():
            if not np.any(mask):
                continue
                
            region_real = np.array(residuals_real)[mask]
            region_imag = np.array(residuals_imag)[mask]

            # Check for systematic bias in each region
            mean_real = region_real.mean()
            mean_imag = region_imag.mean()
            rms_real = np.sqrt(np.mean(region_real**2))
            rms_imag = np.sqrt(np.mean(region_imag**2))

            # Score based on worst regional RMS
            regional_error = max(rms_real, rms_imag * 10)  # Weight imaginary part more
            max_regional_error = max(max_regional_error, regional_error)

            # Warn if systematic bias in a region
            if abs(mean_real) > 0.01:
                warnings.append(f"Systematic bias in {region_name} frequency Dk: mean error = {mean_real:.3f}")
            if abs(mean_imag) > 0.001:
                warnings.append(f"Systematic bias in {region_name} frequency Df: mean error = {mean_imag:.3f}")

        # Score: penalize heavily for regional errors
        if max_regional_error < 0.01:
            score = 100
        elif max_regional_error < 0.02:
            score = 80
        elif max_regional_error < 0.05:
            score = 60
        else:
            score = 30

        return score, warnings

    def evaluate(self, report: Dict[str, Any], noise_levels: Dict[str, float] = None) -> ReportEvaluation:
        """
        Validate & evaluate using thresholds scaled to dataset noise.
        noise_levels should provide {'rms_real': sigma_Dk, 'rms_imag': sigma_Df}.
        """
        required = {
            'n_data_points', 'n_variables', 'reduced_chi_square',
            'rms_real', 'rms_imag', 'mean_real', 'mean_imag',
            'correlations', 'params', 'n_terms'
        }
        missing = required - report.keys()
        if missing:
            raise KeyError(f"Missing required report fields: {missing}")

        # Add optional fields with defaults
        f_ghz_range = report.get('f_ghz_range', (0.5, 110))  # Default range
        residuals_real = report.get('residuals_real', [])
        residuals_imag = report.get('residuals_imag', [])
        f_ghz = report.get('f_ghz', [])

        self._validate_report(report)

        # Estimate noise if not provided
        if noise_levels is None:
            noise_levels = {
                'rms_real': np.std(report.get('residuals_real', [0])),
                'rms_imag': np.std(report.get('residuals_imag', [0])),
                'reduced_chi_square': 1.0,  # Use 1.0 as base for chi-square
                'mean_residual': min(np.std(report.get('residuals_real', [0])), 
                                   np.std(report.get('residuals_imag', [0])))
            }

        # Build scaled thresholds
        scaled_thresh = {}
        for name, (mg, me, mgd, sugg) in self.DEFAULT_THRESHOLDS.items():
            σ = noise_levels.get(name, 1.0)
            scaled_thresh[name] = (mg*σ, me*σ, mgd*σ, sugg)

        metrics: Dict[str, MetricResult] = {}
        suggestions: List[str] = []
        params = report['params']
        n_terms = report['n_terms']

        # Get model-specific warnings
        warnings = self._validate_hybrid_model(params, n_terms)

        # Check frequency range validity
        freq_warnings = self._validate_frequency_range(params, n_terms, f_ghz_range)
        warnings.extend(freq_warnings)

        # Construct data properties for dynamic weight adaptation
        dpv = report['n_data_points'] / report['n_variables']
        freq_span = np.log10(f_ghz_range[1] / f_ghz_range[0]) if f_ghz_range[0] > 0 else 3.0
        sigma_real = noise_levels.get('rms_real', 1.0)
        sigma_imag = noise_levels.get('rms_imag', 1.0)
        
        data_props = {
            'dpv': dpv,
            'freq_span': freq_span,
            'sigma_real': sigma_real,
            'sigma_imag': sigma_imag
        }
        
        # Update weights based on current data properties (but preserve UI weights if set)
        if not hasattr(self, 'ui_weights') or not self.ui_weights:
            self.weights = self._adapt_weights(self.base_weights, data_props)
        else:
            # When UI weights are set, just update data_props for potential minimal adaptations
            self.data_props = data_props
            self.weights = self._adapt_weights(self.base_weights, data_props)
        
        # Data-points-per-variable
        dpv_score, dpv_cat = self._evaluate_inverse_scalar(dpv, (10, 20, 30))
        dpv_sug = "Collect more data or reduce number of terms" if dpv_cat == "Poor" else None
        metrics['dpv'] = MetricResult('dpv', dpv_score, dpv_cat, dpv, dpv_sug)
        if dpv_sug:
            suggestions.append(dpv_sug)

        # Standard scalar metrics using scaled thresholds
        mean_res = max(abs(report['mean_real']), abs(report['mean_imag']))

        # Use scaled thresholds for evaluation
        report_vals = dict(report)
        report_vals['mean_residual'] = mean_res

        for metric in ('rms_real', 'rms_imag', 'mean_residual', 'reduced_chi_square'):
            g, e, gd, suggestion = scaled_thresh[metric]
            val = report_vals.get(metric, 0)
            score, cat = self._evaluate_scalar(val, (g, e, gd))
            sugg = suggestion if cat == "Poor" else None
            metrics[metric] = MetricResult(metric, score, cat, val, sugg)
            if sugg:
                suggestions.append(sugg)

        # Check for systematic errors in frequency regions
        if residuals_real and residuals_imag and f_ghz:
            regional_score, regional_warnings = self._evaluate_systematic_residuals(
                residuals_real, residuals_imag, f_ghz
            )
            metrics['regional_fit'] = MetricResult(
                'regional_fit', regional_score,
                "Good" if regional_score >= 60 else "Poor",
                100 - regional_score,
                "Fit quality varies across frequency range" if regional_score < 60 else None
            )
            warnings.extend(regional_warnings)

        # Tau separation metric
        taus = sorted([params[f'tau{i+1}'] for i in range(n_terms)])
        if len(taus) > 1:
            tau_ratios = [taus[i+1]/taus[i] for i in range(len(taus)-1)]
            min_tau_sep = min(tau_ratios)
        else:
            min_tau_sep = float('inf')

        tau_score, tau_cat = self._evaluate_inverse_scalar(min_tau_sep, (2, 5, 10))
        tau_sug = "Terms too close in frequency - consider reducing N" if tau_cat == "Poor" else None
        metrics['tau_separation'] = MetricResult('tau_separation', tau_score, tau_cat, min_tau_sep, tau_sug)
        if tau_sug:
            suggestions.append(tau_sug)

        # Contribution metrics
        A_vals = [params[f'A{i+1}'] for i in range(n_terms)]
        total_A = sum(A_vals)
        if total_A > 0:
            contributions = [A/total_A for A in A_vals]
            min_contrib = min(contributions)
            max_contrib = max(contributions)
        else:
            min_contrib = 0
            max_contrib = 0

        # Min contribution - penalize heavily for very small contributions
        if min_contrib < 0.01:
            min_score = 30  # Poor
        elif min_contrib < 0.05:
            min_score = 60  # Acceptable
        else:
            min_score = 100  # Good

        min_cat = "Poor" if min_score == 30 else "Acceptable" if min_score == 60 else "Good"
        min_sug = "Remove terms with <1% contribution" if min_contrib < 0.01 else None
        metrics['min_contribution'] = MetricResult('min_contribution', min_score, min_cat, min_contrib, min_sug)
        if min_sug:
            suggestions.append(min_sug)

        # Max contribution
        max_score = 100 if max_contrib < 0.95 else 30  # Heavily penalize dominance
        max_cat = "Good" if max_contrib < 0.95 else "Poor"
        max_sug = "Term dominates - reduce to single term model" if max_contrib > 0.95 else None
        metrics['max_contribution'] = MetricResult('max_contribution', max_score, max_cat, max_contrib, max_sug)
        if max_sug:
            suggestions.append(max_sug)

        # General correlations - stricter evaluation
        corrs = report['correlations']
        if corrs:
            # Count high correlations
            high_corr_count = sum(1 for _, v in corrs.items() if abs(v) > 0.9)
            very_high_corr_count = sum(1 for _, v in corrs.items() if abs(v) > 0.95)

            worst_pair, worst_val = max(corrs.items(), key=lambda kv: abs(kv[1]))

            # Penalize based on number of high correlations
            if very_high_corr_count > 0:
                corr_score = 30  # Poor
                corr_sug = f"{very_high_corr_count} parameter pairs nearly identical"
            elif high_corr_count > 2:
                corr_score = 50  # Bad
                corr_sug = f"{high_corr_count} parameter pairs highly correlated"
            else:
                corr_score, _, corr_sug = self._evaluate_correlation(worst_val)
        else:
            corr_score, corr_sug = 100, None
            worst_pair, worst_val = None, 0.0

        corr_cat = "Poor" if corr_score <= 30 else "Bad" if corr_score <= 50 else "Moderate" if corr_score <= 80 else "Good"

        metrics['correlation'] = MetricResult(
            'correlation', corr_score, corr_cat,
            worst_val, corr_sug, details={'pair': worst_pair}
        )
        if corr_sug:
            suggestions.append(corr_sug)

        # Like-parameter correlations
        like_score, like_warnings = self._evaluate_like_parameter_correlations(corrs, n_terms)
        metrics['like_param_correlation'] = MetricResult(
            'like_param_correlation', like_score,
            "Low" if like_score >= 80 else "High",
            100 - like_score, None
        )
        warnings.extend(like_warnings)

        # Complexity penalty
        complexity_score = self._calculate_complexity_penalty(n_terms, len(warnings))
        metrics['complexity_penalty'] = MetricResult(
            'complexity_penalty', complexity_score,
            "Low" if complexity_score >= 80 else "High",
            100 - complexity_score, None
        )

        # BIC metric for model selection
        if 'information_criteria' in report and report['information_criteria']:
            ic = report['information_criteria']
            bic = ic.get('BIC', 0)
            n_data = ic.get('n_data', report['n_data_points'])
            
            # Normalize BIC to 0-100 score (lower BIC is better)
            # Scale factor may need tuning based on typical BIC ranges
            bic_score = 100 - 10 * (bic / n_data) if n_data > 0 else 50
            bic_score = max(min(bic_score, 100), 0)  # Clamp to [0, 100]
            
            bic_cat = "Good" if bic_score >= 70 else "Fair" if bic_score >= 50 else "Poor"
            bic_sug = "Consider reducing model complexity" if bic_score < 50 else None
            
            metrics['bic'] = MetricResult('bic', bic_score, bic_cat, bic, bic_sug)
            if bic_sug:
                suggestions.append(bic_sug)

        # Calculate overall score using class weights
        weights = self.weights
        total_weight = sum(weights.get(k, 0) for k in metrics)
        overall_score = sum(
            metrics[k].score * weights.get(k, 1)
            for k in metrics
            if k in weights
        ) / total_weight

        # More stringent overall categorization
        if overall_score >= 85:
            overall_cat = "Excellent"
        elif overall_score >= 70:
            overall_cat = "Good"
        elif overall_score >= 50:
            overall_cat = "Fair"
        else:
            overall_cat = "Poor"

        overall = MetricResult("overall", round(overall_score, 1), overall_cat, round(overall_score, 1))

        return ReportEvaluation(
            metrics=metrics,
            overall=overall,
            suggestions=list(set(suggestions)),
            warnings=warnings
        )

# Global variables to store data
global_f_ghz = None
global_complex_epsilon = None
global_measured_dk = None
global_measured_df = None
global_evaluator = None
current_json_data = None

def set_ui_weights(ui_weights):
    """Set user interface weights for the global evaluator."""
    global global_evaluator
    if global_evaluator is None:
        global_evaluator = HybridModelEvaluator()
    
    # Convert PyProxy to Python dict if needed
    if hasattr(ui_weights, 'to_py'):
        ui_weights = ui_weights.to_py()
    
    print(f"Setting UI weights: {ui_weights}")
    print(f"Original base weights: {global_evaluator.base_weights}")
    
    # Update the evaluator's base weights with UI preferences
    for weight_name, weight_value in ui_weights.items():
        if weight_name in global_evaluator.base_weights:
            old_value = global_evaluator.base_weights[weight_name]
            global_evaluator.base_weights[weight_name] = weight_value
            print(f"  {weight_name}: {old_value} -> {weight_value}")
    
    # Safety check: ensure at least one weight is positive
    if all(v == 0 for v in global_evaluator.base_weights.values()):
        global_evaluator.base_weights['dpv'] = 1.0  # Use dpv as failsafe
        print("All weights were zero, setting dpv failsafe to 1.0")
    
    # Store the UI weights to prevent them from being overridden
    global_evaluator.ui_weights = ui_weights.copy()
    
    # Re-adapt weights with UI preferences taking priority
    old_weights = global_evaluator.weights.copy()
    global_evaluator.weights = global_evaluator._adapt_weights(
        global_evaluator.base_weights, 
        global_evaluator.data_props
    )
    print(f"Final weights: {global_evaluator.weights}")
    
    # Check if weights actually changed
    weight_changes = {}
    for key in global_evaluator.weights:
        if key in old_weights:
            if old_weights[key] != global_evaluator.weights[key]:
                weight_changes[key] = f"{old_weights[key]} -> {global_evaluator.weights[key]}"
    
    if weight_changes:
        print(f"Weight changes detected: {weight_changes}")
    else:
        print("No weight changes detected - this might be why score isn't changing")
    
    return True  # Sentinel value for await synchronization

def reevaluate_with_current_weights():
    """Re-run the evaluator on the last fit with the *current* weights."""
    global global_evaluator, current_json_data
    if global_evaluator is None or current_json_data is None:
        return None  # let JS handle the null
    
    # Debug: Print current weights
    print(f"Current evaluator weights: {global_evaluator.weights}")
    
    report_data = global_evaluator.from_json_report(current_json_data)
    
    # Re-inject the extra arrays – they are still in current_json_data
    report_data.update({
        'f_ghz_range': current_json_data.get('f_ghz_range', (0.5, 110)),
        'residuals_real': current_json_data.get('residuals_real', []),
        'residuals_imag': current_json_data.get('residuals_imag', []),
        'f_ghz': current_json_data.get('f_ghz', [])
    })
    
    # Noise estimates (fall back to None gracefully)
    ic = current_json_data.get('information_criteria', {})
    noise_levels = None
    if ic:
        noise_levels = {
            'rms_real': ic.get('sigma_real', 1.0),
            'rms_imag': ic.get('sigma_df', 1.0),
            'reduced_chi_square': 1.0,
            'mean_residual': min(ic.get('sigma_real', 1.0), ic.get('sigma_df', 1.0))
        }
    
    evaluation = global_evaluator.evaluate(report_data, noise_levels)
    print(f"New overall score: {evaluation.overall.score}")
    
    # Debug: Print individual metric scores
    for metric_name, metric_result in evaluation.metrics.items():
        print(f"  {metric_name}: {metric_result.score}")
    
    return evaluation.to_dict()

def calibrate_weights_from_labeled_data(labeled_fits, max_iterations=100):
    """
    Weight calibration tool for learning optimal weights from labeled data.
    
    Args:
        labeled_fits: List of tuples (json_data, true_label) where:
            - json_data: Fit results in JSON format
            - true_label: Expert rating (0-100 scale)
        max_iterations: Maximum optimization iterations
    
    Returns:
        Dictionary of learned weights
    """
    from scipy.optimize import minimize
    import numpy as np
    
    if not labeled_fits:
        return HybridModelEvaluator.HYBRID_WEIGHTS.copy()
    
    # Extract features and labels
    evaluator = HybridModelEvaluator()
    feature_vectors = []
    labels = []
    
    for json_data, true_label in labeled_fits:
        try:
            report_data = evaluator.from_json_report(json_data)
            evaluation = evaluator.evaluate(report_data)
            
            # Create feature vector from individual metric scores
            metrics = evaluation.metrics
            feature_vector = []
            metric_names = []
            
            for metric_name in evaluator.base_weights.keys():
                if metric_name in metrics:
                    feature_vector.append(metrics[metric_name].score)
                    metric_names.append(metric_name)
                else:
                    feature_vector.append(0.0)  # Default for missing metrics
                    metric_names.append(metric_name)
            
            feature_vectors.append(feature_vector)
            labels.append(true_label)
            
        except Exception as e:
            print(f"Warning: Skipping invalid fit data: {e}")
            continue
    
    if not feature_vectors:
        print("No valid training data found")
        return evaluator.base_weights.copy()
    
    feature_vectors = np.array(feature_vectors)
    labels = np.array(labels)
    
    # Define objective function for weight optimization
    def objective(weights):
        predicted_scores = []
        for features in feature_vectors:
            # Calculate weighted score
            total_weight = sum(weights)
            if total_weight == 0:
                predicted_score = 0
            else:
                predicted_score = sum(features[i] * weights[i] for i in range(len(weights))) / total_weight
            predicted_scores.append(predicted_score)
        
        # Mean squared error
        mse = np.mean((np.array(predicted_scores) - labels) ** 2)
        return mse
    
    # Initial weights (normalized)
    initial_weights = list(evaluator.base_weights.values())
    initial_weights = np.array(initial_weights) / sum(initial_weights)
    
    # Constraints: weights must be non-negative and sum to something reasonable
    bounds = [(0, 10) for _ in initial_weights]  # Allow weights up to 10
    
    # Optimize weights
    try:
        result = minimize(objective, initial_weights, bounds=bounds, 
                         method='L-BFGS-B', options={'maxiter': max_iterations})
        
        if result.success:
            learned_weights = result.x
            # Convert back to dictionary format
            weight_dict = {}
            for i, metric_name in enumerate(evaluator.base_weights.keys()):
                weight_dict[metric_name] = float(learned_weights[i])
            
            print(f"Weight calibration completed successfully")
            print(f"Final MSE: {result.fun:.4f}")
            return weight_dict
        else:
            print(f"Weight optimization failed: {result.message}")
            return evaluator.base_weights.copy()
            
    except Exception as e:
        print(f"Error during weight optimization: {e}")
        return evaluator.base_weights.copy()

def load_data(csv_content):
    global global_f_ghz, global_complex_epsilon, global_measured_dk, global_measured_df
    try:
        data = pd.read_csv(io.StringIO(csv_content)).dropna()
        f_ghz = data.iloc[:, 0].values
        dk = data.iloc[:, 1].values
        df = data.iloc[:, 2].values
        complex_epsilon = dk - 1j * (dk * df)
        global_f_ghz = f_ghz
        global_complex_epsilon = complex_epsilon
        global_measured_dk = dk.tolist()
        global_measured_df = df.tolist()
        return f_ghz, complex_epsilon
    except Exception as e:
        raise ValueError(f"Failed to parse CSV: {e}")

def estimate_initial_parameters(f_ghz, complex_epsilon, n_terms):
    """
    Generates robust initial guesses for Hybrid model parameters.
    Uses logarithmic spacing for tau values to better cover frequency extremes.
    """
    dk = np.real(complex_epsilon)
    n_pts = dk.size

    # High-frequency permittivity using plateau averaging
    if n_pts >= 3:
        n_avg = max(3, int(n_pts * 0.05))            # at least 3 points or 5%
        eps_inf_init = float(np.mean(dk[-n_avg:]))   # plateau average
    else:
        eps_inf_init = float(dk[-1]) if n_pts else 1.0

    # Compute log-spaced "center" frequencies
    f_min, f_max = f_ghz.min(), f_ghz.max()
    log_min, log_max = np.log10(f_min), np.log10(f_max)
    # n_terms points between log_min and log_max, exclusive of endpoints:
    f_centers = np.logspace(log_min, log_max, n_terms + 2)[1:-1]

    params = {'eps_inf': eps_inf_init}
    delta_eps_total = dk[0] - dk[-1] if dk.size else 1.0
    A_init = delta_eps_total / n_terms

    for i, f_center in enumerate(f_centers):
        # Geometric spacing => one decade-even coverage
        tau_init = 1 / (2 * np.pi * f_center * 1e9)

        # Keep α, γ defaults or refine later
        alpha_init = 0.8
        gamma_init = 0.9
        
        # Initial beta value (mix parameter)
        beta_init = 0.5

        params[f'A{i+1}']     = A_init
        params[f'tau{i+1}']   = tau_init
        params[f'alpha{i+1}'] = alpha_init
        params[f'gamma{i+1}'] = gamma_init
        params[f'beta{i+1}']  = beta_init

    return params

def calculate_hybrid_model(params, f_ghz, n_terms):
    """Calculate Hybrid Debye-Lorentz model response"""
    # Ensure f_ghz is a numpy array
    f_ghz = np.asarray(f_ghz)
    omega = 2 * np.pi * f_ghz * 1e9

    eps_inf = float(params['eps_inf'])
    complex_epsilon = np.ones_like(omega, dtype=complex) * eps_inf

    for i in range(n_terms):
        A = float(params[f'A{i+1}'])
        tau = float(params[f'tau{i+1}'])
        alpha = float(params[f'alpha{i+1}'])
        gamma = float(params[f'gamma{i+1}'])
        beta = float(params[f'beta{i+1}'])        # new mix parameter

        # Compute the complex argument once
        omega_tau = omega * tau
        ph = np.log(1j * omega_tau)        # consistent complex logarithm
        # Raise to fractional power via exp(alpha * log(...))
        debye_term = A / (1 + np.exp(alpha * ph))

        # Lorentz-like term (corrected as in Problem 1)
        omega_0 = 1 / tau
        lorentz_term = A * omega_0**2 / (omega_0**2 - omega**2 + 1j * gamma * omega)

        # **use beta to blend**
        complex_epsilon += beta * debye_term + (1 - beta) * lorentz_term

    return complex_epsilon

def residual(params, f_ghz, complex_epsilon_data, n_terms, weight_df=2.0):
    p_dict = params.valuesdict()
    eps_mod = calculate_hybrid_model(p_dict, f_ghz, n_terms)

    # Real-part residual (Dk)
    real_mod = np.real(eps_mod)
    real_meas = np.real(complex_epsilon_data)
    res_real = real_mod - real_meas

    # Loss-tangent residual (Df)
    df_mod  = -np.imag(eps_mod) / real_mod
    df_meas = -np.imag(complex_epsilon_data) / real_meas
    res_df  = df_mod - df_meas

    # Stack with heavier weighting on Df
    return np.concatenate([
        res_real,
        weight_df * res_df
    ])

def _dict_to_parameters(params_dict: dict):
    """Helper: turn a simple dict into an lmfit.Parameters object."""
    p = Parameters()
    for name, val in params_dict.items():
        p.add(name, value=val)
    return p

def calculate_jacobian(params_dict, f_ghz, complex_epsilon_data, n_terms, h=1e-8):
    """
    Compute the Jacobian of the *residual* function w.r.t. each parameter
    by finite differences.
    """
    # Parameter ordering must match what you pass to residual()
    param_names = ['eps_inf']
    for i in range(n_terms):
        param_names.extend([f'A{i+1}', f'tau{i+1}', f'alpha{i+1}', f'gamma{i+1}', f'beta{i+1}'])

    # Base residual vector (length = 2*N_data: Dk + weighted Df)
    base_params = _dict_to_parameters(params_dict)
    base_res = residual(base_params, f_ghz, complex_epsilon_data, n_terms)  # returns 1D np.array
    n_data = base_res.size

    # Prepare Jacobian matrix: rows = data-points, cols = parameters
    J = np.zeros((n_data, len(param_names)))

    # Finite-difference for each parameter
    for i, name in enumerate(param_names):
        # Make a fresh copy for each perturbation
        perturbed = params_dict.copy()
        perturbed[name] += h

        p_plus = _dict_to_parameters(perturbed)
        res_plus = residual(p_plus, f_ghz, complex_epsilon_data, n_terms)

        # Derivative ≈ [ r(θ+h) – r(θ) ] / h
        J[:, i] = (res_plus - base_res) / h

    return J

def calculate_correlation_matrix(params_dict, f_ghz, complex_epsilon_data, n_terms):
    """
    Calculate correlation matrix from the Jacobian of the *residual* function.
    Returns a (P×P) numpy array, or raises a ValueError if it cannot be computed.
    """
    # Build Jacobian on residuals (see Problem 6)
    J = calculate_jacobian(params_dict, f_ghz, complex_epsilon_data, n_terms)

    # Compute JTJ
    JTJ = J.T @ J

    # Regularize if ill-conditioned
    cond = np.linalg.cond(JTJ)
    if cond > 1e12:
        raise ValueError(f"Jacobian matrix ill-conditioned (cond={cond:.2e})")

    # Invert
    cov = np.linalg.inv(JTJ + np.eye(JTJ.shape[0]) * 1e-12)

    # Build correlation
    stddevs = np.sqrt(np.diag(cov))
    
    # Check for zero or negative variances
    if np.any(stddevs <= 0):
        raise ValueError("Invalid variances detected in covariance matrix")
    
    corr = cov / np.outer(stddevs, stddevs)
    return corr

def get_user_friendly_message(technical_message):
    """Convert technical optimization messages to user-friendly language"""
    message_map = {
        "xtol termination condition is satisfied.":
            "Parameters converged to stable values (changes < 0.00000001)",
        "ftol termination condition is satisfied.":
            "Fit quality stabilized (improvement < 0.00000001)",
        "gtol termination condition is satisfied.":
            "Found optimal solution (gradient near zero)",
        "Maximum number of iterations reached.":
            "Stopped at iteration limit - consider increasing iterations or adjusting initial parameters",
        "Both xtol and ftol termination conditions are satisfied.":
            "Excellent convergence - both parameters and fit quality stabilized",
        "Optimization terminated successfully.":
            "Found optimal parameters successfully",
        "The relative error between two consecutive iterates is at most xtol.":
            "Parameters converged to stable values",
        "Number of iterations exceeded max_nfev.":
            "Reached maximum function evaluations - may need more iterations"
    }

    # Check if we have a user-friendly version
    for tech_msg, friendly_msg in message_map.items():
        if tech_msg in technical_message:
            return friendly_msg

    # If no match, return a generic friendly message with the technical one
    if "satisfied" in technical_message.lower():
        return "Optimization converged successfully ({})".format(technical_message)
    else:
        return "Optimization completed ({})".format(technical_message)

def format_correlation_matrix(corr_matrix, n_terms):
    """Format correlation matrix for display"""
    if corr_matrix is None or corr_matrix.size == 0:
        return "Unable to calculate correlation matrix"

    param_names = ['eps_inf']
    for i in range(n_terms):
        param_names.extend([f'A{i+1}', f'tau{i+1}', f'alpha{i+1}', f'gamma{i+1}', f'beta{i+1}'])

    result = "Correlations:\\n"

    # Check matrix dimensions
    if len(corr_matrix.shape) != 2 or corr_matrix.shape[0] != corr_matrix.shape[1]:
        return "Invalid correlation matrix dimensions"

    max_idx = min(len(param_names), corr_matrix.shape[0])
    
    for i in range(max_idx):
        for j in range(i+1, max_idx):  # Only show upper triangle
            correlation = corr_matrix[i, j]
            if abs(correlation) > 0.1:  # Only show significant correlations
                param1 = param_names[i] if i < len(param_names) else f"param_{i}"
                param2 = param_names[j] if j < len(param_names) else f"param_{j}"
                result += f"    ({param1}, {param2}) = {correlation:+.4f}\\n"

    return result

def create_plotly_plot(f_ghz, measured_eps, fitted_eps):
    fig = make_subplots(rows=2, cols=1, subplot_titles=('Real Permittivity', 'Loss Tangent'))
    fig.add_trace(go.Scatter(x=f_ghz, y=np.real(measured_eps), mode='markers', name='Measured Dk', marker=dict(color='black')), row=1, col=1)
    fig.add_trace(go.Scatter(x=f_ghz, y=np.real(fitted_eps), mode='lines', name='Fitted Dk', line=dict(color='red')), row=1, col=1)
    measured_df = -np.imag(measured_eps) / np.real(measured_eps)
    fitted_df = -np.imag(fitted_eps) / np.real(fitted_eps)
    fig.add_trace(go.Scatter(x=f_ghz, y=measured_df, mode='markers', name='Measured Df', marker=dict(color='black'), showlegend=False), row=2, col=1)
    fig.add_trace(go.Scatter(x=f_ghz, y=fitted_df, mode='lines', name='Fitted Df', line=dict(color='red'), showlegend=False), row=2, col=1)
    fig.update_xaxes(title_text="Frequency (GHz)", row=1, col=1)
    fig.update_yaxes(title_text="Dielectric Constant (Dk)", row=1, col=1)
    fig.update_xaxes(title_text="Frequency (GHz)", row=2, col=1)
    fig.update_yaxes(title_text="Dissipation Factor (Df)", row=2, col=1)
    fig.update_layout(height=600, margin=dict(l=20, r=20, t=40, b=20), template="plotly_white", legend=dict(yanchor="top", y=0.99, xanchor="right", x=0.99))
    return pio.to_json(fig)

def create_downloadable_plot(fitted_params, n_terms):
    global global_f_ghz, global_complex_epsilon
    if global_f_ghz is None:
        return None

    # Ensure params is a proper Python dict
    if hasattr(fitted_params, 'to_py'):
        fitted_params = fitted_params.to_py()

    fitted_epsilon = calculate_hybrid_model(fitted_params, global_f_ghz, n_terms)

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6))

    ax1.plot(global_f_ghz, np.real(global_complex_epsilon), 'ko', label='Measured')
    ax1.plot(global_f_ghz, np.real(fitted_epsilon), 'r-', lw=2, label='Fitted')
    ax1.set_xlabel('Frequency (GHz)')
    ax1.set_ylabel('Dielectric Constant (Dk)')
    ax1.set_title('Real Permittivity')
    ax1.legend()
    ax1.grid(True, alpha=0.5)

    measured_df = -np.imag(global_complex_epsilon) / np.real(global_complex_epsilon)
    fitted_df = -np.imag(fitted_epsilon) / np.real(fitted_epsilon)
    ax2.plot(global_f_ghz, measured_df, 'ko', label='Measured')
    ax2.plot(global_f_ghz, fitted_df, 'r-', lw=2, label='Fitted')
    ax2.set_xlabel('Frequency (GHz)')
    ax2.set_ylabel('Dissipation Factor (Df)')
    ax2.set_title('Loss Tangent')
    ax2.legend()
    ax2.grid(True, alpha=0.5)

    plt.tight_layout()

    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=150)
    plt.close(fig)
    buf.seek(0)
    return buf.getvalue()

def get_user_friendly_method(method):
    """Convert technical method names to user-friendly descriptions"""
    method_map = {
        "least_squares": "Levenberg-Marquardt (robust nonlinear least squares)",
        "nelder": "Nelder-Mead Simplex (derivative-free optimization)",
        "lbfgsb": "L-BFGS-B (memory-efficient quasi-Newton method)"
    }
    return method_map.get(method, method)

def run_analysis(csv_content, n_terms, method):
    global global_f_ghz, global_complex_epsilon, current_json_data, global_evaluator
    f_ghz, complex_epsilon_data = load_data(csv_content)

    initial_params = estimate_initial_parameters(f_ghz, complex_epsilon_data, n_terms)
    params = Parameters()

    # --- Compute data-driven bounds ---
    dk_vals = np.real(complex_epsilon_data)
    dk_min, dk_max = dk_vals.min(), dk_vals.max()
    delta_eps = dk_max - dk_min
    
    # Bound eps_inf to within ±20% of high-freq plateau
    eps_inf_min = max(0.5 * dk_max, 0.0)
    eps_inf_max = 1.2 * dk_max

    # Frequency span (GHz → Hz)
    f_min_hz = f_ghz.min() * 1e9
    f_max_hz = f_ghz.max() * 1e9
    # Relaxation time bounds: [0.1/(2πf_max), 10/(2πf_min)]
    tau_min = 0.1 / (2 * np.pi * f_max_hz)
    tau_max = 10.0 / (2 * np.pi * f_min_hz)

    # Register eps_inf
    params.add(
        'eps_inf',
        value=initial_params['eps_inf'],
        min=eps_inf_min,
        max=eps_inf_max
    )

    # Register each term with data-driven bounds
    for i in range(n_terms):
        # Amplitude
        params.add(
            f'A{i+1}',
            value=initial_params[f'A{i+1}'],
            min=0.0,
            max=1.2 * delta_eps
        )
        # Relaxation time
        params.add(
            f'tau{i+1}',
            value=initial_params[f'tau{i+1}'],
            min=tau_min,
            max=tau_max
        )
        # Debye exponent
        params.add(
            f'alpha{i+1}',
            value=initial_params[f'alpha{i+1}'],
            min=0.01,
            max=1.0
        )
        # Damping
        params.add(
            f'gamma{i+1}',
            value=initial_params[f'gamma{i+1}'],
            min=0.0,
            max=10.0
        )
        # Mix parameter
        params.add(
            f'beta{i+1}',
            value=initial_params[f'beta{i+1}'],
            min=0.0,
            max=1.0
        )

    minimizer = Minimizer(residual, params, fcn_args=(f_ghz, complex_epsilon_data, n_terms, 2.0))
    result = minimizer.minimize(method=method)

    fit_params = {p: float(v.value) for p, v in result.params.items()}

    # Calculate residuals and statistics
    fitted_epsilon = calculate_hybrid_model(result.params.valuesdict(), f_ghz, n_terms)
    
    # Compute residuals exactly as in the residual function
    real_mod = np.real(fitted_epsilon)
    real_meas = np.real(complex_epsilon_data)
    res_real = real_mod - real_meas

    # Compute loss-tangent residuals
    df_mod = -np.imag(fitted_epsilon) / real_mod
    df_meas = -np.imag(complex_epsilon_data) / real_meas
    res_df = df_mod - df_meas

    # Same weight used in residual() function
    weight_df = 2.0

    # Build the residual vector exactly as in residual()
    resid_vec = np.concatenate([res_real, weight_df * res_df])

    # Now χ² is sum of squares of that exact vector
    chi_sqr = np.sum(resid_vec**2)
    n_dat = resid_vec.size
    n_var = 1 + 5 * n_terms  # eps_inf + 5 params per term (A, tau, alpha, gamma, beta)
    dof = n_dat - n_var if n_dat > n_var else 1
    red_chi_sqr = chi_sqr / dof

    # Calculate correlation matrix with error handling
    try:
        corr_matrix = calculate_correlation_matrix(result.params.valuesdict(), f_ghz, complex_epsilon_data, n_terms)
        corr_text = format_correlation_matrix(corr_matrix, n_terms)
    except Exception as e:
        # Log the error, but continue
        logger.warning(f"Could not compute correlation matrix: {e}")
        # Fallback: zeros of the right size
        P = 1 + 5 * n_terms  # eps_inf + 5 params per term (A, tau, alpha, gamma, beta)
        corr_matrix = np.zeros((P, P))
        corr_text = f"Correlation matrix computation failed: {e}"

    # Create JSON data structure first (before using it)
    json_data = {
        "model": "Hybrid Debye-Lorentz",
        "n_terms": n_terms,
        "timestamp": datetime.now().isoformat(),
        "parameters": fit_params,
        "fit_statistics": {
            "n_data_points": n_dat,
            "n_variables": n_var,
            "chi_square": chi_sqr,
            "reduced_chi_square": red_chi_sqr
        },
        "residual_analysis": {
            "real_part": {
                "mean": float(np.mean(res_real)),
                "std_dev": float(np.std(res_real)),
                "rms": float(np.sqrt(np.mean(res_real**2)))
            },
            "loss_tangent": {
                "mean": float(np.mean(res_df)),
                "std_dev": float(np.std(res_df)),
                "rms": float(np.sqrt(np.mean(res_df**2)))
            }
        },
        "correlation_matrix": corr_matrix.tolist()
    }

    # Calculate information criteria with proper normalization
    # 1) Estimate/mechanism to supply noise levels σ_Dk, σ_Df:
    sigma_real = np.std(res_real)   # or instrument spec
    sigma_df   = np.std(res_df)     # ditto

    # 2) Use the exact weighted residuals, then normalize
    weighted_res_real = res_real / sigma_real
    weighted_res_df = (weight_df * res_df) / sigma_df

    # 3) Stack into effective residual vector (consistent with optimization)
    resid_eff = np.concatenate([weighted_res_real, weighted_res_df])
    n_eff = resid_eff.size

    # 4) Effective chi-square
    chi2_eff = np.sum(resid_eff**2)

    # 5) AIC / BIC using the Gaussian-noise log-likelihood
    # (dropping constant ln(2π) term)
    aic = chi2_eff + 2 * n_var
    bic = chi2_eff + n_var * np.log(n_eff)

    # 6) (Optional) small-sample AICc
    if n_eff - n_var - 1 > 0:
        AIC_c = aic + (2*n_var*(n_var+1))/(n_eff - n_var - 1)
    else:
        AIC_c = np.inf

    # Add to JSON data
    json_data['information_criteria'] = {
        'AIC': float(aic),
        'BIC': float(bic),
        'AIC_c': float(AIC_c),
        'n_data': n_eff,
        'n_params': n_var,
        'chi2_eff': float(chi2_eff),
        'sigma_real': float(sigma_real),
        'sigma_df': float(sigma_df)
    }

    # Create model description
    model_desc = f"""Hybrid Debye-Lorentz Model with {n_terms} term(s)
--------------------------------------------------
ε(ω) = ε_inf + Σ[i=1 to {n_terms}] H_i(ω)

where each hybrid term H_i combines Debye and Lorentz characteristics:
H_i(ω) = β_i * A_i / (1 + (jωτ_i)^α_i) + (1-β_i) * A_i * ω_0i² / (ω_0i² - ω² - jγ_i*ω)

with ω_0i = 1/τ_i as the resonance frequency and β_i as the mixing parameter.
"""

    # Format parameters for report
    params_text = "Fitted Parameters:\\n"
    params_text += f"    eps_inf = {fit_params['eps_inf']:.4f}\\n"
    for i in range(n_terms):
        params_text += f"\\n    Term {i+1}:\\n"
        params_text += f"        A{i+1}     = {fit_params[f'A{i+1}']:.4f}\\n"
        params_text += f"        tau{i+1}   = {fit_params[f'tau{i+1}']:.4e} s\\n"
        params_text += f"        alpha{i+1} = {fit_params[f'alpha{i+1}']:.4f}\\n"
        params_text += f"        gamma{i+1} = {fit_params[f'gamma{i+1}']:.4f}\\n"
        params_text += f"        beta{i+1}  = {fit_params[f'beta{i+1}']:.4f}\\n"
        params_text += f"        f_0{i+1}   = {1/(2*np.pi*fit_params[f'tau{i+1}'])/1e9:.4f} GHz\\n"

    # Create full report
    full_report = f"""Hybrid Debye-Lorentz Fit Report
{'=' * 50}
Date: {datetime.now()}

{model_desc}

{params_text}

Fit Statistics
--------------------------------------------------
    # data points      = {n_dat}
    # variables        = {n_var}
    chi-square         = {chi_sqr:.4f}
    reduced chi-square = {red_chi_sqr:.4f}

Residual Analysis
--------------------------------------------------
    Real Part (Dk):
        Mean: {np.mean(res_real):.4f}
        Std Dev: {np.std(res_real):.4f}
        RMS: {np.sqrt(np.mean(res_real**2)):.4f}

    Loss Tangent (Df):
        Mean: {np.mean(res_df):.4f}
        Std Dev: {np.std(res_df):.4f}
        RMS: {np.sqrt(np.mean(res_df**2)):.4f}

Term Analysis
--------------------------------------------------"""

    # Add term analysis
    A_values = [fit_params[f'A{i+1}'] for i in range(n_terms)]
    total_A = sum(A_values)

    for i in range(n_terms):
        f0 = 1/(2*np.pi*fit_params[f'tau{i+1}'])/1e9
        contribution = fit_params[f'A{i+1}']/total_A*100 if total_A > 0 else 0
        alpha = fit_params[f'alpha{i+1}']
        gamma = fit_params[f'gamma{i+1}']
        beta = fit_params[f'beta{i+1}']

        character = 'Debye-like' if alpha < 0.5 else 'Hybrid' if alpha < 0.8 else 'Lorentz-like'
        damping = 'Low' if gamma < 0.5 else 'High' if gamma > 1.5 else 'Moderate'
        mix_character = 'Pure Debye' if beta > 0.9 else 'Pure Lorentz' if beta < 0.1 else f'{beta*100:.0f}% Debye, {(1-beta)*100:.0f}% Lorentz'

        full_report += f"""
    Term {i+1}:
        Resonance frequency: {f0:.3f} GHz
        Relative contribution: {contribution:.1f}%
        Character: {character} (α={alpha:.2f})
        Damping: {damping} (γ={gamma:.2f})
        Mixing: {mix_character} (β={beta:.2f})"""

    # Add information criteria section
    ic_section = ""
    if json_data.get('information_criteria'):
        ic = json_data['information_criteria']
        ic_section = f"""
Model Selection Criteria
--------------------------------------------------
    AIC  = {ic['AIC']:.2f} (Akaike Information Criterion)
    BIC  = {ic['BIC']:.2f} (Bayesian Information Criterion)
    AIC_c = {ic['AIC_c']:.2f} (Corrected AIC for small samples)

    Note: Lower values indicate better model. BIC penalizes complexity
    more strongly than AIC, especially for larger datasets.
"""

    full_report += f"""

{corr_text}
{ic_section}
Optimization Summary
--------------------------------------------------
Method Used: {method}
Fitting Status: {"✓ Completed Successfully" if result.success else "✗ Failed"}
Convergence Details: {get_user_friendly_message(result.message)}
"""

    # Store global data BEFORE evaluation attempt
    global_evaluator = HybridModelEvaluator()
    
    # Store JSON data with additional fields needed for re-evaluation
    json_data['f_ghz_range'] = (min(f_ghz), max(f_ghz))
    json_data['residuals_real'] = res_real.tolist()
    json_data['residuals_imag'] = res_df.tolist()
    json_data['f_ghz'] = f_ghz.tolist()
    current_json_data = json_data

    # Evaluate the fit
    try:
        evaluator = global_evaluator  # reuse
        report_data = HybridModelEvaluator.from_json_report(json_data)
        # Add additional data for better evaluation
        report_data['f_ghz_range'] = (min(f_ghz), max(f_ghz))
        report_data['residuals_real'] = res_real.tolist()
        report_data['residuals_imag'] = res_df.tolist()  # Now using loss tangent residuals
        report_data['f_ghz'] = f_ghz.tolist()
        # Add measured data
        report_data['measured_dk'] = np.real(complex_epsilon_data).tolist()
        report_data['measured_df'] = (-np.imag(complex_epsilon_data) / np.real(complex_epsilon_data)).tolist()
        
        # Pass noise levels to evaluator
        noise_levels = {
            'rms_real': sigma_real,
            'rms_imag': sigma_df,
            'reduced_chi_square': 1.0,
            'mean_residual': min(sigma_real, sigma_df)
        }
        evaluation = evaluator.evaluate(report_data, noise_levels)
        json_data['evaluation'] = evaluation.to_dict()
        
    except Exception as e:
        logger.warning(f"Could not evaluate fit: {e}")
        json_data['evaluation'] = None

    plot_json = create_plotly_plot(f_ghz, complex_epsilon_data, fitted_epsilon)

    return_data = {
        "report": full_report,
        "plot_json": plot_json,
        "f_ghz": f_ghz.tolist(),
        "fitted_params": fit_params,
        "json_data": json_data,
        "n_terms": n_terms,
        "measured_dk": global_measured_dk,
        "measured_df": global_measured_df
    }
    return json.dumps(return_data)
`;

        async function main() {
            setLoadingState(true, 'Initializing Environment...');
            try {
                pyodide = await loadPyodide({
                    indexURL: "https://cdn.jsdelivr.net/pyodide/v0.24.1/full/"
                });
                setLoadingState(true, 'Loading Python Packages...');
                await pyodide.loadPackage(['numpy', 'pandas', 'micropip', 'matplotlib']);
                const micropip = pyodide.pyimport('micropip');
                setLoadingState(true, 'Installing lmfit & plotly...');
                await micropip.install(['lmfit', 'plotly']);
                isPyodideReady = true;
                await pyodide.runPythonAsync(pythonScript);
                setLoadingState(false);
            } catch (err) {
                isPyodideReady = false;
                showError(`Failed to initialize Python environment: ${err}`);
                setLoadingState(false);
            }
        }

        function setLoadingState(isLoading, message = '') {
            statusMessage.textContent = message;
            statusDiv.style.display = isLoading ? 'flex' : 'none';
            runButton.disabled = isLoading;
            runButton.classList.toggle('btn-disabled', isLoading);
            if (!isLoading) updateButtonState();
        }

        function showError(message) {
            errorMessage.textContent = message;
            errorBox.classList.remove('hidden');
            outputDiv.classList.add('hidden');
        }

        function hideError() {
            errorBox.classList.add('hidden');
        }

        function updateButtonState() {
            const isReady = isPyodideReady && !!fileContent;
            runButton.disabled = !isReady;
            runButton.classList.toggle('btn-disabled', !isReady);
        }

        function displayParameters(params, n_terms) {
            parametersDisplay.innerHTML = '';
            paramControls = {};

            // eps_inf
            const epsInfDiv = document.createElement('div');
            epsInfDiv.className = 'pb-3 border-b border-gray-200';
            epsInfDiv.innerHTML = `
                <div class="font-medium mb-2">ε<sub>∞</sub> (Epsilon Infinity)</div>
                <div class="space-y-1">
                    <input type="range" id="eps_inf_slider" class="w-full">
                    <div class="flex items-center justify-between">
                        <input type="number" id="eps_inf_input" class="param-input" step="0.01">
                        <span class="text-xs text-gray-500">Range: <span id="eps_inf_range"></span></span>
                    </div>
                </div>
            `;
            parametersDisplay.appendChild(epsInfDiv);

            paramControls['eps_inf'] = {
                slider: epsInfDiv.querySelector('#eps_inf_slider'),
                input: epsInfDiv.querySelector('#eps_inf_input'),
                rangeSpan: epsInfDiv.querySelector('#eps_inf_range')
            };

            // Terms
            for (let i = 0; i < n_terms; i++) {
                const termDiv = document.createElement('div');
                termDiv.className = 'pt-3 pb-3 border-b border-gray-200';
                termDiv.innerHTML = `
                    <div class="font-medium mb-2">Term ${i + 1}</div>
                    <div class="space-y-2">
                        <!-- A parameter -->
                        <div>
                            <div class="text-xs text-gray-600 mb-1">A<sub>${i+1}</sub> (Amplitude)</div>
                            <input type="range" id="A${i+1}_slider" class="w-full">
                            <div class="flex items-center justify-between">
                                <input type="number" id="A${i+1}_input" class="param-input" step="0.01">
                                <span class="text-xs text-gray-500">Range: <span id="A${i+1}_range"></span></span>
                            </div>
                        </div>
                        <!-- tau parameter -->
                        <div>
                            <div class="text-xs text-gray-600 mb-1">τ<sub>${i+1}</sub> (Relaxation time)</div>
                            <input type="range" id="tau${i+1}_slider" class="w-full">
                            <div class="flex items-center justify-between">
                                <input type="number" id="tau${i+1}_input" class="param-input" step="1e-14">
                                <span class="text-xs text-gray-500">Range: <span id="tau${i+1}_range"></span></span>
                            </div>
                        </div>
                        <!-- alpha parameter -->
                        <div>
                            <div class="text-xs text-gray-600 mb-1">α<sub>${i+1}</sub> (Debye parameter)</div>
                            <input type="range" id="alpha${i+1}_slider" class="w-full">
                            <div class="flex items-center justify-between">
                                <input type="number" id="alpha${i+1}_input" class="param-input" step="0.01">
                                <span class="text-xs text-gray-500">Range: <span id="alpha${i+1}_range"></span></span>
                            </div>
                        </div>
                        <!-- gamma parameter -->
                        <div>
                            <div class="text-xs text-gray-600 mb-1">γ<sub>${i+1}</sub> (Lorentz damping)</div>
                            <input type="range" id="gamma${i+1}_slider" class="w-full">
                            <div class="flex items-center justify-between">
                                <input type="number" id="gamma${i+1}_input" class="param-input" step="0.01">
                                <span class="text-xs text-gray-500">Range: <span id="gamma${i+1}_range"></span></span>
                            </div>
                        </div>
                        <!-- beta parameter -->
                        <div>
                            <div class="text-xs text-gray-600 mb-1">β<sub>${i+1}</sub> (Mix parameter)</div>
                            <input type="range" id="beta${i+1}_slider" class="w-full">
                            <div class="flex items-center justify-between">
                                <input type="number" id="beta${i+1}_input" class="param-input" step="0.01">
                                <span class="text-xs text-gray-500">Range: <span id="beta${i+1}_range"></span></span>
                            </div>
                        </div>
                        <!-- f0 display -->
                        <div class="flex items-center justify-between bg-gray-50 p-2 rounded">
                            <span class="text-xs text-gray-600">f<sub>0,${i+1}</sub> (Resonance):</span>
                            <span id="f0_${i+1}_display" class="text-sm font-medium"></span>
                        </div>
                    </div>
                `;
                parametersDisplay.appendChild(termDiv);

                // Add controls for this term
                const termParams = ['A', 'tau', 'alpha', 'gamma', 'beta'];
                termParams.forEach(param => {
                    const key = `${param}${i+1}`;
                    paramControls[key] = {
                        slider: termDiv.querySelector(`#${key}_slider`),
                        input: termDiv.querySelector(`#${key}_input`),
                        rangeSpan: termDiv.querySelector(`#${key}_range`)
                    };
                });

                // Add f0 display reference
                paramControls[`f0_${i+1}_display`] = termDiv.querySelector(`#f0_${i+1}_display`);
            }

            // Set up controls with values and ranges
            setupParameterControls(params, n_terms);
        }

        function setupParameterControls(params, n_terms) {
            // Store original parameters for reset
            originalParams = {...params};

            // Set up eps_inf
            const eps_inf_val = params.eps_inf;
            const eps_inf_range = {
                min: Math.max(0.5, eps_inf_val * 0.5),
                max: Math.min(10, eps_inf_val * 2),
                step: 0.01
            };

            setControlValues('eps_inf', eps_inf_val, eps_inf_range);

            // Set up term parameters
            for (let i = 0; i < n_terms; i++) {
                // A parameter
                const A_val = params[`A${i+1}`];
                const A_range = {
                    min: 0,
                    max: Math.max(10, A_val * 3),
                    step: 0.01
                };
                setControlValues(`A${i+1}`, A_val, A_range);

                // tau parameter (logarithmic scale)
                const tau_val = params[`tau${i+1}`];
                const tau_range = {
                    min: 1e-13,
                    max: 1e-6,
                    step: 1e-14,
                    logScale: true
                };
                setControlValues(`tau${i+1}`, tau_val, tau_range);

                // alpha parameter
                const alpha_val = params[`alpha${i+1}`];
                const alpha_range = {
                    min: 0.1,
                    max: 1.0,
                    step: 0.01
                };
                setControlValues(`alpha${i+1}`, alpha_val, alpha_range);

                // gamma parameter
                const gamma_val = params[`gamma${i+1}`];
                const gamma_range = {
                    min: 0.1,
                    max: 3.0,
                    step: 0.01
                };
                setControlValues(`gamma${i+1}`, gamma_val, gamma_range);

                // beta parameter
                const beta_val = params[`beta${i+1}`];
                const beta_range = {
                    min: 0.0,
                    max: 1.0,
                    step: 0.01
                };
                setControlValues(`beta${i+1}`, beta_val, beta_range);

                // Update f0 display
                updateF0Display(i, tau_val);
            }

            // Add event listeners
            setupEventListeners(n_terms);
        }

        function setControlValues(paramName, value, range) {
            const control = paramControls[paramName];
            if (!control) return;

            const { slider, input, rangeSpan } = control;

            if (range.logScale) {
                // For logarithmic parameters like tau
                const logMin = Math.log10(range.min);
                const logMax = Math.log10(range.max);
                const logValue = Math.log10(value);

                slider.min = 0;
                slider.max = 100;
                slider.value = ((logValue - logMin) / (logMax - logMin)) * 100;

                input.value = value.toExponential(2);
                input.step = range.step;
                rangeSpan.textContent = `${range.min.toExponential(0)} - ${range.max.toExponential(0)}`;
            } else {
                slider.min = range.min;
                slider.max = range.max;
                slider.step = range.step;
                slider.value = value;

                input.min = range.min;
                input.max = range.max;
                input.step = range.step;
                input.value = value;

                rangeSpan.textContent = `${range.min.toFixed(2)} - ${range.max.toFixed(2)}`;
            }
        }

        function updateF0Display(termIndex, tauValue) {
            const f0Display = paramControls[`f0_${termIndex+1}_display`];
            if (f0Display) {
                const f0_ghz = 1 / (2 * Math.PI * tauValue) / 1e9;
                f0Display.textContent = `${f0_ghz.toFixed(2)} GHz`;
            }
        }

        function setupEventListeners(n_terms) {
            let updateTimeout;

            // eps_inf listeners
            const epsInfControl = paramControls['eps_inf'];
            if (epsInfControl) {
                epsInfControl.slider.addEventListener('input', (e) => {
                    epsInfControl.input.value = e.target.value;
                    clearTimeout(updateTimeout);
                    updateTimeout = setTimeout(() => updateUIFromControls(n_terms), 50);
                });

                epsInfControl.input.addEventListener('input', (e) => {
                    epsInfControl.slider.value = e.target.value;
                    clearTimeout(updateTimeout);
                    updateTimeout = setTimeout(() => updateUIFromControls(n_terms), 50);
                });
            }

            // Term parameter listeners
            for (let i = 0; i < n_terms; i++) {
                // Regular parameters (A, alpha, gamma, beta)
                ['A', 'alpha', 'gamma', 'beta'].forEach(param => {
                    const key = `${param}${i+1}`;
                    const control = paramControls[key];
                    if (control) {
                        control.slider.addEventListener('input', (e) => {
                            control.input.value = e.target.value;
                            clearTimeout(updateTimeout);
                            updateTimeout = setTimeout(() => updateUIFromControls(n_terms), 50);
                        });

                        control.input.addEventListener('input', (e) => {
                            control.slider.value = e.target.value;
                            clearTimeout(updateTimeout);
                            updateTimeout = setTimeout(() => updateUIFromControls(n_terms), 50);
                        });
                    }
                });

                // tau parameter (logarithmic)
                const tauControl = paramControls[`tau${i+1}`];
                if (tauControl) {
                    tauControl.slider.addEventListener('input', (e) => {
                        const logMin = Math.log10(1e-13);
                        const logMax = Math.log10(1e-6);
                        const logValue = logMin + (e.target.value / 100) * (logMax - logMin);
                        const value = Math.pow(10, logValue);
                        tauControl.input.value = value.toExponential(2);
                        updateF0Display(i, value);
                        clearTimeout(updateTimeout);
                        updateTimeout = setTimeout(() => updateUIFromControls(n_terms), 50);
                    });

                    tauControl.input.addEventListener('input', (e) => {
                        const value = parseFloat(e.target.value);
                        const logMin = Math.log10(1e-13);
                        const logMax = Math.log10(1e-6);
                        const logValue = Math.log10(value);
                        tauControl.slider.value = ((logValue - logMin) / (logMax - logMin)) * 100;
                        updateF0Display(i, value);
                        clearTimeout(updateTimeout);
                        updateTimeout = setTimeout(() => updateUIFromControls(n_terms), 50);
                    });
                }
            }
        }

        async function updateUIFromControls(n_terms) {
            if (!currentData || !pyodide) return;

            // Gather current parameter values
            const params = {
                eps_inf: parseFloat(paramControls['eps_inf'].input.value)
            };

            for (let i = 0; i < n_terms; i++) {
                params[`A${i+1}`] = parseFloat(paramControls[`A${i+1}`].input.value);
                params[`tau${i+1}`] = parseFloat(paramControls[`tau${i+1}`].input.value);
                params[`alpha${i+1}`] = parseFloat(paramControls[`alpha${i+1}`].input.value);
                params[`gamma${i+1}`] = parseFloat(paramControls[`gamma${i+1}`].input.value);
                params[`beta${i+1}`] = parseFloat(paramControls[`beta${i+1}`].input.value);
            }

            try {
                // Update Plot
                const calculateFunc = pyodide.globals.get('calculate_hybrid_model');
                // Convert params to Python dict using pyodide
                const pyParams = pyodide.toPy(params);
                const pyFGhz = pyodide.toPy(currentData.f_ghz);
                const modelProxy = calculateFunc(pyParams, pyFGhz, n_terms);

                // Convert complex array properly
                const real = pyodide.globals.get('np').real(modelProxy).toJs();
                const imag = pyodide.globals.get('np').imag(modelProxy).toJs();

                modelProxy.destroy();
                pyParams.destroy();
                pyFGhz.destroy();

                const fittedDk = real;
                const fittedDf = fittedDk.map((dk, i) => dk === 0 ? 0 : -imag[i] / dk);

                Plotly.restyle('plot-output', { y: [fittedDk, fittedDf] }, [1, 3]);

                // Update Report
                const real_residuals = fittedDk.map((dk, i) => dk - currentData.measured_dk[i]);
                const df_residuals = fittedDf.map((df, i) => df - currentData.measured_df[i]);

                const n_dat = real_residuals.length + df_residuals.length;
                const n_var = 1 + 5 * n_terms;
                const chi_sqr = real_residuals.reduce((sum, r) => sum + r*r, 0) +
                               df_residuals.reduce((sum, r) => sum + (2.0 * r)*(2.0 * r), 0);  // Apply same weighting
                const red_chi_sqr = chi_sqr / (n_dat - n_var);

                // Update report text
                let paramsText = `eps_inf = ${params.eps_inf.toFixed(4)}\n`;
                for (let i = 0; i < n_terms; i++) {
                    paramsText += `\nTerm ${i+1}:\n`;
                    paramsText += `    A${i+1}     = ${params[`A${i+1}`].toFixed(4)}\n`;
                    paramsText += `    tau${i+1}   = ${params[`tau${i+1}`].toExponential(4)} s\n`;
                    paramsText += `    alpha${i+1} = ${params[`alpha${i+1}`].toFixed(4)}\n`;
                    paramsText += `    gamma${i+1} = ${params[`gamma${i+1}`].toFixed(4)}\n`;
                    paramsText += `    beta${i+1}  = ${params[`beta${i+1}`].toFixed(4)}\n`;
                    paramsText += `    f_0${i+1}   = ${(1/(2*Math.PI*params[`tau${i+1}`])/1e9).toFixed(4)} GHz\n`;
                }

                const reportText = reportOutput.textContent;
                const updatedReport = reportText.replace(
                    /Fitted Parameters:[\s\S]*?Fit Statistics/,
                    `Fitted Parameters:\n    ${paramsText}\nFit Statistics`
                );

                // Update statistics in report
                const statsUpdate = updatedReport.replace(
                    /chi-square\s*=\s*[\d.]+/,
                    `chi-square         = ${chi_sqr.toFixed(4)}`
                ).replace(
                    /reduced chi-square\s*=\s*[\d.]+/,
                    `reduced chi-square = ${red_chi_sqr.toFixed(4)}`
                );

                reportOutput.textContent = statsUpdate;

                // Update fit quality indicator
                // Create a simple evaluation based on reduced chi-square
                const score = red_chi_sqr < 1e-4 ? 100 :
                             red_chi_sqr < 1e-3 ? 80 :
                             red_chi_sqr < 1e-2 ? 60 : 30;
                const category = score >= 90 ? "Godly" :
                                score >= 75 ? "Excellent" :
                                score >= 60 ? "Good" : "Poor";

                updateFitQualityIndicator({
                    overall_score: score,
                    overall_category: category
                });

            } catch (err) {
                console.error('Error updating UI:', err);
            }
        }

        function resetParameters() {
            if (!originalParams || !currentData) return;
            const n_terms = currentData.n_terms;
            setupParameterControls(originalParams, n_terms);
            updateUIFromControls(n_terms);
        }

        function updateFitQualityIndicator(evaluation) {
            const indicator = document.getElementById('fit-quality-indicator');
            const scoreSpan = document.getElementById('fit-quality-score');
            const bar = document.getElementById('fit-quality-bar');

            if (!evaluation) {
                indicator.classList.add('hidden');
                return;
            }

            indicator.classList.remove('hidden');
            const score = evaluation.overall_score;
            const category = evaluation.overall_category;

            scoreSpan.textContent = `${score} (${category})`;

            // Update bar width and color
            bar.style.width = `${score}%`;

            if (score >= 90) {
                bar.className = 'h-2 rounded-full transition-all duration-300 bg-green-500';
                indicator.className = 'mb-4 p-3 rounded-lg bg-green-50 border border-green-200';
            } else if (score >= 75) {
                bar.className = 'h-2 rounded-full transition-all duration-300 bg-blue-500';
                indicator.className = 'mb-4 p-3 rounded-lg bg-blue-50 border border-blue-200';
            } else if (score >= 60) {
                bar.className = 'h-2 rounded-full transition-all duration-300 bg-yellow-500';
                indicator.className = 'mb-4 p-3 rounded-lg bg-yellow-50 border border-yellow-200';
            } else {
                bar.className = 'h-2 rounded-full transition-all duration-300 bg-red-500';
                indicator.className = 'mb-4 p-3 rounded-lg bg-red-50 border border-red-200';
            }

            // Update radar chart
            updateRadarChart(evaluation);
        }

        function updateRadarChart(evaluation) {
            if (!evaluation || !evaluation.metrics) return;

            const radarContainer = document.getElementById('radar-chart-container');
            const radarDiv = document.getElementById('radar-chart');

            // Extract metric names and scores, excluding 'overall'
            const metrics = evaluation.metrics;
            const metricNames = Object.keys(metrics).filter(name => name !== 'overall');
            const metricScores = metricNames.map(name => metrics[name].score);
            
            // Create user-friendly labels
            const labelMap = {
                'dpv': 'Data/Param Ratio',
                'reduced_chi_square': 'Chi-Square Fit',
                'rms_real': 'RMS Real',
                'rms_imag': 'RMS Imaginary',
                'mean_residual': 'Systematic Bias',
                'regional_fit': 'Regional Fit',
                'tau_separation': 'Frequency Sep.',
                'min_contribution': 'Min Contribution',
                'max_contribution': 'Max Contribution',
                'correlation': 'Correlations',
                'like_param_correlation': 'Similar Params',
                'complexity_penalty': 'Complexity',
                'bic': 'Model Selection'
            };
            
            const friendlyLabels = metricNames.map(name => labelMap[name] || name);

            // Create radar chart
            const trace = {
                type: 'scatterpolar',
                r: metricScores,
                theta: friendlyLabels,
                fill: 'toself',
                name: 'Metric Scores',
                line: { color: '#3B82F6' },
                fillcolor: 'rgba(59, 130, 246, 0.2)'
            };

            const layout = {
                polar: {
                    radialaxis: {
                        visible: true,
                        range: [0, 100],
                        tickfont: { size: 9 },
                        gridcolor: '#E5E7EB'
                    },
                    angularaxis: {
                        tickfont: { size: 8 }
                    }
                },
                showlegend: false,
                margin: { t: 30, b: 30, l: 30, r: 30 },
                font: { size: 9 },
                width: undefined,
                height: 280
            };

            try {
                Plotly.newPlot(radarDiv, [trace], layout, { 
                    responsive: true, 
                    displayModeBar: false,
                    staticPlot: false
                });
                
                // Force resize after a short delay to ensure proper fitting
                setTimeout(() => {
                    Plotly.Plots.resize(radarDiv);
                }, 100);
                
                radarContainer.classList.remove('hidden');
            } catch (error) {
                console.error('Error creating radar chart:', error);
                // Fallback to text display if Plotly fails
                radarDiv.innerHTML = `
                    <div class="text-xs text-gray-600">
                        <div class="grid grid-cols-2 gap-2">
                            ${metricNames.map((name, i) => 
                                `<div class="flex justify-between">
                                    <span>${friendlyLabels[i]}:</span>
                                    <span class="font-mono">${metricScores[i].toFixed(1)}</span>
                                </div>`
                            ).join('')}
                        </div>
                    </div>
                `;
                radarContainer.classList.remove('hidden');
            }
        }

        async function downloadResults() {
            if (!currentData) return;
            setLoadingState(true, 'Preparing download...');
            try {
                const zip = new JSZip();
                const baseFilename = originalFilename.replace(/\.csv$/i, '');
                const n_terms = currentData.n_terms;

                // Get current parameters from controls
                const params = {
                    eps_inf: parseFloat(paramControls['eps_inf'].input.value)
                };

                for (let i = 0; i < n_terms; i++) {
                    params[`A${i+1}`] = parseFloat(paramControls[`A${i+1}`].input.value);
                    params[`tau${i+1}`] = parseFloat(paramControls[`tau${i+1}`].input.value);
                    params[`alpha${i+1}`] = parseFloat(paramControls[`alpha${i+1}`].input.value);
                    params[`gamma${i+1}`] = parseFloat(paramControls[`gamma${i+1}`].input.value);
                    params[`beta${i+1}`] = parseFloat(paramControls[`beta${i+1}`].input.value);
                }

                // 1. Create Fitted Data CSV
                const calculateFunc = pyodide.globals.get('calculate_hybrid_model');
                const pyParams = pyodide.toPy(params);
                const pyFGhz = pyodide.toPy(currentData.f_ghz);
                const fitted_epsilon_proxy = calculateFunc(pyParams, pyFGhz, n_terms);

                // Convert complex array properly
                const real = pyodide.globals.get('np').real(fitted_epsilon_proxy).toJs();
                const imag = pyodide.globals.get('np').imag(fitted_epsilon_proxy).toJs();

                fitted_epsilon_proxy.destroy();
                pyParams.destroy();
                pyFGhz.destroy();

                let csvContent = "Frequency_GHz,fitted_Dk,fitted_Df\n";
                currentData.f_ghz.forEach((f, i) => {
                    const dk = real[i];
                    const df = dk === 0 ? 0 : -imag[i] / dk;
                    csvContent += `${f},${dk},${df}\n`;
                });
                zip.file(`${baseFilename}_fitted_hybrid.csv`, csvContent);

                // 2. Add Matplotlib Plot Image
                const createPlotFunc = pyodide.globals.get('create_downloadable_plot');
                const pyParamsForPlot = pyodide.toPy(params);
                const imageProxy = createPlotFunc(pyParamsForPlot, n_terms);
                const imageData = imageProxy.toJs();
                imageProxy.destroy();
                pyParamsForPlot.destroy();
                zip.file(`${baseFilename}_plot_hybrid.png`, imageData);

                // 3. Add Report (human-readable .txt)
                zip.file(`${baseFilename}_report_hybrid.txt`, reportOutput.textContent);

                // 4. Generate JSON report for database ingestion
                const fullJsonReport = {
                    model: "Hybrid Debye-Lorentz",
                    n_terms: n_terms,
                    timestamp: new Date().toISOString(),
                    input_file: originalFilename,
                    parameters: params,
                    data: {
                        frequency_ghz: currentData.f_ghz,
                        measured: {
                            dk: currentData.measured_dk,
                            df: currentData.measured_df
                        },
                        fitted: {
                            dk: real,
                            df: real.map((dk, i) => {
                                return dk === 0 ? 0 : -imag[i] / dk;
                            })
                        }
                    }
                };

                zip.file(`${baseFilename}_report_hybrid.json`, JSON.stringify(fullJsonReport, null, 2));

                // 5. Generate and Download Zip
                const content = await zip.generateAsync({ type: "blob" });
                const link = document.createElement("a");
                link.href = URL.createObjectURL(content);
                link.download = `${baseFilename}_hybrid_results.zip`;
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);

            } catch(err) {
                showError(`Failed to create download package: ${err}`);
            } finally {
                setLoadingState(false);
            }
        }

        // Set up event listeners
        fileUpload.addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (file) {
                originalFilename = file.name;
                const reader = new FileReader();
                reader.onload = (e) => {
                    fileContent = e.target.result;
                    updateButtonState();
                };
                reader.readAsText(file);
            } else {
                fileContent = null;
                originalFilename = '';
                updateButtonState();
            }
        });

        runButton.addEventListener('click', async () => {
            if (!fileContent || !pyodide) return;
            hideError();
            setLoadingState(true, 'Running analysis...');
            outputDiv.classList.add('hidden');

            try {
                const runAnalysis = pyodide.globals.get('run_analysis');
                const n_terms = parseInt(nTermsSelect.value);
                const fitMethod = fitMethodSelect.value;
                const resultJson = runAnalysis(fileContent, n_terms, fitMethod);
                const result = JSON.parse(resultJson);

                currentData = result;

                const plotData = JSON.parse(result.plot_json);
                plotOutput.innerHTML = '';
                Plotly.newPlot('plot-output', plotData.data, plotData.layout, {responsive: true});

                reportOutput.textContent = result.report;
                displayParameters(result.fitted_params, n_terms);

                // Show fit quality
                if (result.json_data.evaluation) {
                    updateFitQualityIndicator(result.json_data.evaluation);
                }

                outputDiv.classList.remove('hidden');

            } catch (err) {
                console.error(err);
                showError(`An error occurred during analysis: ${err.message}`);
            } finally {
                setLoadingState(false);
            }
        });

        resetButton.addEventListener('click', resetParameters);
        downloadButton.addEventListener('click', downloadResults);

        // Initialize scoring preferences UI
        function initializeScoringPreferences() {
            const applyButton = document.getElementById('apply-scoring-prefs');
            const scoringPrefs = document.getElementById('scoring-prefs');

            // Update slider value displays
            const sliders = ['weight-regional_fit', 'weight-rms_real', 'weight-rms_imag', 'weight-reduced_chi_square', 'weight-bic'];
            sliders.forEach(sliderId => {
                const slider = document.getElementById(sliderId);
                const valueDisplay = document.getElementById(sliderId + '-value');
                
                slider.addEventListener('input', () => {
                    valueDisplay.textContent = slider.value;
                });
            });

            // Apply scoring preferences
            applyButton.addEventListener('click', async (e) => {
                e.preventDefault();
                e.stopPropagation();
                
                console.log('Apply button clicked'); // Debug log
                
                // Collect slider values
                const uiWeights = {};
                sliders.forEach(sliderId => {
                    const weightName = sliderId.replace('weight-', '');
                    const sliderElement = document.getElementById(sliderId);
                    if (sliderElement) {
                        uiWeights[weightName] = parseFloat(sliderElement.value);
                    } else {
                        console.warn(`Slider element ${sliderId} not found`);
                    }
                });
                
                console.log('Collected UI weights:', uiWeights);

                // Guard: check if analysis has been run
                const ge = pyodide.globals.get('global_evaluator');
                if (!currentData || !ge || ge === null) {
                    console.log('No analysis data found. Please run analysis first.');
                    setLoadingState(false);
                    return;
                }

                try {
                    setLoadingState(true, 'Updating scores...');
                    
                    // 1. Wait until Python finishes
                    await pyodide.globals.get('set_ui_weights')(pyodide.toPy(uiWeights));
                    
                    // 2. Call helper and convert safely
                    const evalProxy = await pyodide.globals.get('reevaluate_with_current_weights')();
                    if (!evalProxy) {
                        console.error('No evaluation data available');
                        setLoadingState(false);
                        return;
                    }
                    
                    // Convert the PyProxy → plain JS object, not a Map
                    const evaluation = (evalProxy && evalProxy.toJs)
                          ? evalProxy.toJs({ dict_converter: Object.fromEntries })
                          : evalProxy;
                    
                    console.log('Previous score:', document.getElementById('fit-quality-score')?.textContent);
                    updateFitQualityIndicator(evaluation);
                    console.log('New score:', evaluation.overall_score);
                    console.log('Updated evaluation:', evaluation);
                    
                } catch (error) {
                    console.error('Error applying scoring preferences:', error);
                } finally {
                    setLoadingState(false);
                }
            });

            // Show scoring prefs when analysis completes
            const observer = new MutationObserver((mutations) => {
                mutations.forEach((mutation) => {
                    if (mutation.type === 'childList' && mutation.target.id === 'parameters-display') {
                        if (mutation.target.children.length > 0) {
                            scoringPrefs.classList.remove('hidden');
                        }
                    }
                });
            });
            
            observer.observe(document.getElementById('parameters-display'), { childList: true });
        }

        // Initialize
        main();
        updateButtonState();
        initializeScoringPreferences();

        // --- Split-pane resizing (Plot pane ↔ Parameter pane) ---
        (function () {
          const dragbar     = document.getElementById('dragbar');
          const paneLeft    = document.getElementById('pane-left');
          const plotDiv     = document.getElementById('plot-output');

          let startX, startWidth;

          // mouse down ─► start dragging
          dragbar.addEventListener('mousedown', e => {
            startX      = e.clientX;
            startWidth  = paneLeft.getBoundingClientRect().width;
            document.body.classList.add('select-none');      // avoid text selection
            window.addEventListener('mousemove', onDrag);
            window.addEventListener('mouseup',   stopDrag);
          });

          function onDrag (e) {
            const newWidth = Math.max(360, startWidth + (e.clientX - startX));  // 360 = min-width
            paneLeft.style.width = newWidth + 'px';
            // Let Plotly redraw smoothly but throttle to every animation frame
            window.requestAnimationFrame(() => Plotly.Plots.resize(plotDiv));
          }

          function stopDrag () {
            window.removeEventListener('mousemove', onDrag);
            window.removeEventListener('mouseup',   stopDrag);
            document.body.classList.remove('select-none');
            // Final resize (especially if user releases quickly)
            Plotly.Plots.resize(plotDiv);
          }

          // Ensure plot resizes on window resize
          window.addEventListener('resize', () => Plotly.Plots.resize(plotDiv));
        })();

        // ── draggable KPI wrapper ─────────────────────────────────────────────
        (function () {
          const wrapper   = document.getElementById('kpi-wrapper');
          if (!wrapper) return;

          let startX, startY, startLeft, startTop, dragging = false;

          const getPos = e => ({
            x: e.touches ? e.touches[0].clientX : e.clientX,
            y: e.touches ? e.touches[0].clientY : e.clientY
          });

          const startDrag = e => {
            // Allow Plotly interactions inside the radar chart and toggle clicks – drag only if user
            // begins on the wrapper itself (not on an inner canvas/element)
            if (e.target.closest('#radar-chart') || e.target.closest('#radar-toggle')) return;

            const p   = getPos(e);
            const box = wrapper.getBoundingClientRect();
            startX = p.x;  startY = p.y;
            startLeft = box.left;  startTop = box.top;

            // Switch to explicit left/top so we can move freely
            wrapper.style.left  = startLeft + 'px';
            wrapper.style.top   = startTop  + 'px';
            wrapper.style.right = 'auto';

            dragging = true;
            wrapper.classList.add('opacity-90');
            document.addEventListener('mousemove', onDrag);
            document.addEventListener('mouseup',   stopDrag);
            document.addEventListener('touchmove', onDrag,  { passive:false });
            document.addEventListener('touchend',  stopDrag);
          };

          const onDrag = e => {
            if (!dragging) return;
            e.preventDefault();                    // avoid scrolling on touch
            const p = getPos(e);
            const dx = p.x - startX;
            const dy = p.y - startY;
            wrapper.style.left = startLeft + dx + 'px';
            wrapper.style.top  = startTop  + dy + 'px';

            // keep the card inside the viewport (optional)
            const rect = wrapper.getBoundingClientRect();
            const vw = window.innerWidth, vh = window.innerHeight;
            if (rect.left < 0) wrapper.style.left = '0px';
            if (rect.top  < 0) wrapper.style.top  = '0px';
            if (rect.right > vw) wrapper.style.left = vw - rect.width + 'px';
            if (rect.bottom > vh) wrapper.style.top = vh - rect.height + 'px';
          };

          const stopDrag = () => {
            dragging = false;
            wrapper.classList.remove('opacity-90');
            document.removeEventListener('mousemove', onDrag);
            document.removeEventListener('mouseup',   stopDrag);
            document.removeEventListener('touchmove', onDrag);
            document.removeEventListener('touchend',  stopDrag);
            // Ensure the radar chart reflows if width changed
            Plotly.Plots.resize(document.getElementById('radar-chart'));
          };

          wrapper.addEventListener('mousedown', startDrag);
          wrapper.addEventListener('touchstart', startDrag, { passive:false });
        })();

        // ── collapsible radar chart ─────────────────────────────────────────────
        (function () {
          const toggle = document.getElementById('radar-toggle');
          const content = document.getElementById('radar-content');
          const chevron = document.getElementById('radar-chevron');
          
          if (!toggle || !content || !chevron) return;
          
          let isCollapsed = false;
          
          toggle.addEventListener('click', (e) => {
            // Don't trigger drag when clicking toggle
            e.stopPropagation();
            
            isCollapsed = !isCollapsed;
            
            if (isCollapsed) {
              content.style.display = 'none';
              chevron.style.transform = 'rotate(-90deg)';
            } else {
              content.style.display = 'block';
              chevron.style.transform = 'rotate(0deg)';
              // Resize Plotly chart when expanded
              setTimeout(() => {
                Plotly.Plots.resize(document.getElementById('radar-chart'));
              }, 100);
            }
          });
        })();
    </script>
</body>
</html>
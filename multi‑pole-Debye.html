<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Multi-Pole Debye Model Fitter</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.32.0.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .spinner {
            border-top-color: #3498db;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        .btn-disabled {
            background-color: #9ca3af;
            cursor: not-allowed;
            opacity: 0.7;
        }
        /* Style for parameter sliders */
        input[type=range] {
            -webkit-appearance: none;
            appearance: none;
            width: 100%;
            height: 8px;
            background: #d1d5db;
            border-radius: 5px;
            outline: none;
            opacity: 0.7;
            transition: opacity .2s;
        }
        input[type=range]:hover {
            opacity: 1;
        }
        input[type=range]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            background: #3b82f6;
            cursor: pointer;
            border-radius: 50%;
        }
        input[type=range]::-moz-range-thumb {
            width: 20px;
            height: 20px;
            background: #3b82f6;
            cursor: pointer;
            border-radius: 50%;
        }
        .pole-controls {
            border-left: 3px solid #3b82f6;
            padding-left: 1rem;
            margin-bottom: 1.5rem;
        }
    </style>
</head>
<body class="bg-gray-100 text-gray-800">

    <div class="container mx-auto p-4 md:p-8 max-w-7xl">
        <header class="text-center mb-8">
            <h1 class="text-3xl md:text-4xl font-bold text-gray-900">Multi-Pole Debye Model Fitter</h1>
            <p class="mt-2 text-lg text-gray-600">Upload your dielectric spectroscopy data (CSV) to fit it to the Multi-Pole Debye model.</p>
        </header>

        <div class="bg-white rounded-xl shadow-lg p-6 md:p-8">
            <!-- Controls Section -->
            <div class="grid grid-cols-1 md:grid-cols-2 gap-6 items-center mb-6">
                <div>
                    <label for="file-upload" class="block text-sm font-medium text-gray-700 mb-2">
                        Upload CSV File
                    </label>
                    <div class="flex items-center space-x-4">
                        <input type="file" id="file-upload" accept=".csv" class="block w-full text-sm text-gray-500
                            file:mr-4 file:py-2 file:px-4
                            file:rounded-lg file:border-0
                            file:text-sm file:font-semibold
                            file:bg-blue-50 file:text-blue-700
                            hover:file:bg-blue-100
                        ">
                    </div>
                    <p class="text-xs text-gray-500 mt-2">
                        CSV columns in order:
                        Frequency&nbsp;(GHz),&nbsp;Dk&nbsp;(real&nbsp;permittivity),
                        Df&nbsp;(loss&nbsp;tangent&nbsp;<em>tan δ</em>)
                    </p>

                </div>
                <div class="space-y-4">
                    <div>
                        <label for="n-poles" class="block text-sm font-medium text-gray-700">Number of Debye Poles</label>
                        <select id="n-poles" class="mt-1 block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-blue-500 focus:border-blue-500 sm:text-sm rounded-md">
                            <option value="auto" selected>Auto-detect</option>
                            <option value="1">1 Pole</option>
                            <option value="2">2 Poles</option>
                            <option value="3">3 Poles</option>
                            <option value="4">4 Poles</option>
                        </select>
                    </div>
                    <div>
                        <label for="fit-method" class="block text-sm font-medium text-gray-700">Optimization Method</label>
                        <select id="fit-method" class="mt-1 block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-blue-500 focus:border-blue-500 sm:text-sm rounded-md">
                            <option value="least_squares" selected>least_squares (Default)</option>
                            <option value="nelder">nelder</option>
                            <option value="lbfgsb">lbfgsb</option>
                        </select>
                    </div>
                    <button id="run-button" class="w-full bg-blue-600 text-white font-bold py-3 px-6 rounded-lg shadow-md hover:bg-blue-700 transition-colors duration-300 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50">
                        Run Analysis
                    </button>
                </div>
            </div>

            <!-- Status and Output Section -->
            <div id="status" class="text-center my-4 p-4 bg-gray-50 rounded-lg hidden">
                <div class="flex items-center justify-center">
                    <div class="spinner w-6 h-6 rounded-full border-4 border-gray-300"></div>
                    <p id="status-message" class="ml-4 text-gray-700 font-medium"></p>
                </div>
            </div>

            <div id="output" class="hidden mt-8">
                <div class="grid grid-cols-1 lg:grid-cols-3 gap-8">
                    <!-- Plot Display -->
                    <div id="plot-container" class="lg:col-span-2 border border-gray-200 rounded-lg bg-gray-50 p-2">
                         <div id="plot-output"></div>
                    </div>

                    <!-- Parameter Controls -->
                    <div id="controls-panel" class="lg:col-span-1 bg-white p-6 rounded-lg border">
                        <div class="flex justify-between items-center mb-4">
                            <h3 class="text-xl font-bold text-gray-800">Adjust Fit Parameters</h3>
                            <div class="flex space-x-2">
                                <button id="reset-button" class="text-sm bg-gray-200 hover:bg-gray-300 text-gray-800 font-semibold py-1 px-3 rounded-lg">
                                    Reset
                                </button>
                                <button id="download-button" class="text-sm bg-blue-500 hover:bg-blue-600 text-white font-semibold py-1 px-3 rounded-lg">
                                    Download
                                </button>
                            </div>
                        </div>

                        <!-- Fit Quality Indicator -->
                        <div id="fit-quality-indicator" class="mb-4 p-3 rounded-lg hidden">
                            <div class="flex items-center justify-between">
                                <span class="text-sm font-medium">Fit Quality:</span>
                                <span id="fit-quality-score" class="text-lg font-bold"></span>
                            </div>
                            <div class="w-full bg-gray-200 rounded-full h-2 mt-2">
                                <div id="fit-quality-bar" class="h-2 rounded-full transition-all duration-300"></div>
                            </div>
                            <!-- Warnings Display -->
                            <div id="fit-warnings" class="mt-3 space-y-1 hidden">
                                <div class="text-xs font-medium text-gray-600 mb-1">Warnings:</div>
                                <div id="warnings-container" class="space-y-1"></div>
                            </div>
                        </div>

                        <div id="params-container" class="space-y-6">
                            <!-- eps_inf -->
                            <div>
                                <label for="eps_inf_slider" class="block text-sm font-medium text-gray-700">ε<sub>∞</sub> (Epsilon Infinity)</label>
                                <input type="range" id="eps_inf_slider" class="mt-1">
                                <input type="number" id="eps_inf_input" class="mt-2 w-full p-2 border border-gray-300 rounded-md text-sm">
                            </div>
                            <!-- Dynamic pole controls will be added here -->
                            <div id="pole-controls-container"></div>
                        </div>
                    </div>
                </div>

                <!-- Report Display -->
                <div class="mt-8">
                    <h2 class="text-2xl font-bold mb-4 text-gray-800">Fit Report</h2>
                    <div class="bg-gray-900 text-white font-mono text-sm p-6 rounded-lg overflow-x-auto">
                        <pre id="report-output"></pre>
                    </div>
                </div>
            </div>
             <!-- Error Display -->
            <div id="error-box" class="hidden mt-6 p-4 bg-red-100 border border-red-400 text-red-700 rounded-lg">
                <h3 class="font-bold">An Error Occurred</h3>
                <p id="error-message"></p>
            </div>
        </div>
        <footer class="text-center mt-8 text-sm text-gray-500">
            <p>Powered by Pyodide, lmfit, and plotly</p>
            <div class="border-t border-gray-300 pt-2 mt-2">
            <p class="font-semibold text-gray-700">Citation</p>
            <p class="italic">Meddeb, B., & Meddeb, A. (2025). QuickFitter: Interactive Dielectric Data Fitting Tool - Multi-Pole Debye Model.
            <br>Available at: <a href="https://github.com/bmeddeb/QuickFitter" class="text-blue-600 hover:underline">https://github.com/bmeddeb/QuickFitter</a></p>
        </div>
        </footer>
    </div>

    <script type="text/javascript">
        // DOM Elements
        const fileUpload = document.getElementById('file-upload');
        const runButton = document.getElementById('run-button');
        const resetButton = document.getElementById('reset-button');
        const downloadButton = document.getElementById('download-button');
        const fitMethodSelect = document.getElementById('fit-method');
        const nPolesSelect = document.getElementById('n-poles');
        const statusDiv = document.getElementById('status');
        const statusMessage = document.getElementById('status-message');
        const outputDiv = document.getElementById('output');
        const plotOutput = document.getElementById('plot-output');
        const reportOutput = document.getElementById('report-output');
        const errorBox = document.getElementById('error-box');
        const errorMessage = document.getElementById('error-message');
        const poleControlsContainer = document.getElementById('pole-controls-container');

        // Global State
        let pyodide = null;
        let fileContent = null;
        let isPyodideReady = false;
        let currentData = null;
        let originalFilename = '';
        let currentPoleControls = {};
        let currentNPoles = 0;

        // Python Script
        const pythonScript = `
import sys
import io
import json
from datetime import datetime
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.io as pio
from lmfit import Minimizer, Parameters, fit_report
import math
import logging
from typing import Dict, Tuple, Any, List, Optional
from dataclasses import dataclass, field
from scipy.signal import find_peaks

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Fit Evaluator Classes (same as before with adapted thresholds)
@dataclass
class MetricResult:
    """Stores the evaluation result for a single metric."""
    name: str
    score: float
    category: str
    value: float
    suggestion: str | None = None
    details: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ReportEvaluation:
    """Stores the full evaluation for a report."""
    metrics: Dict[str, MetricResult]
    overall: MetricResult
    suggestions: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)

    def to_markdown(self) -> str:
        """Return the evaluation as a markdown-formatted table."""
        headers = ["Metric", "Score", "Category", "Value", "Suggestion"]
        lines = ["| " + " | ".join(headers) + " |",
                 "| " + " | ".join(["---"]*len(headers)) + " |"]
        for m in self.metrics.values():
            suggestion = m.suggestion or ""
            lines.append(f"| {m.name} | {m.score} | {m.category} | {m.value:.4g} | {suggestion} |")
        lines.append(
            f"| **Overall** | {self.overall.score} | {self.overall.category} | {self.overall.value} |  |"
        )
        if self.warnings:
            lines.append("\\n**Warnings:**")
            for warning in self.warnings:
                lines.append(f"- {warning}")
        return "\\n".join(lines)

    def to_dict(self) -> Dict[str, Any]:
        """Convert evaluation to dictionary format."""
        return {
            'overall_score': self.overall.score,
            'overall_category': self.overall.category,
            'metrics': {
                k: {
                    'score': v.score,
                    'category': v.category,
                    'value': v.value,
                    'suggestion': v.suggestion,
                    'details': v.details
                }
                for k, v in self.metrics.items()
            },
            'suggestions': self.suggestions,
            'warnings': self.warnings,
            'markdown_table': self.to_markdown()
        }

class FitEvaluator:
    """Evaluates the quality of a fit report based on configurable metrics."""
    DEFAULT_THRESHOLDS: Dict[str, Tuple[float, float, float, str]] = {
        "reduced_chi_square": (1e-4, 1e-3, 1e-2, "Consider adding more poles or adjusting relaxation times."),
        "rms_real":           (0.005, 0.010, 0.020, "Refine initial ε_∞ or pole strengths Δε_i."),
        "rms_imag":           (0.001, 0.002, 0.005, "Add extra pole or adjust time constants τ_i."),
        "mean_residual":      (1e-4, 5e-4, 1e-3, "Check for systematic bias, consider frequency-dependent effects."),
        "aic":                (2, 7, 14, "Consider reducing number of poles."),
        "bic":                (2, 7, 14, "Model complexity not justified by data."),
    }

    DEFAULT_WEIGHTS: Dict[str, int] = {
        'dpv': 1,
        'reduced_chi_square': 3,
        'rms_real': 2,
        'rms_imag': 2,
        'mean_residual': 1,
        'correlation': 2,
        'aic': 2,
        'bic': 2
    }

    def __init__(self, thresholds=None, weights=None):
        self.thresholds = thresholds or FitEvaluator.DEFAULT_THRESHOLDS
        self.weights = weights or FitEvaluator.DEFAULT_WEIGHTS

    @classmethod
    def from_json_report(cls, json_data: Dict[str, Any]) -> Dict[str, Any]:
        """Convert JSON report format to evaluator format."""
        fit_stats = json_data.get('fit_statistics', {})
        residuals = json_data.get('residual_analysis', {})
        corr_matrix = json_data.get('correlation_matrix', [])
        correlations = {}
        if corr_matrix and isinstance(corr_matrix, list):
            n_poles = json_data.get('parameters', {}).get('n_poles', 1)
            param_names = ['eps_inf']
            for i in range(n_poles):
                param_names.extend([f'delta_eps_{i}', f'tau_{i}'])
            try:
                for i in range(len(corr_matrix)):
                    for j in range(i+1, len(corr_matrix[0])):
                        if abs(corr_matrix[i][j]) > 0.1:
                            correlations[(param_names[i], param_names[j])] = corr_matrix[i][j]
            except (IndexError, TypeError) as e:
                logger.warning(f"Error parsing correlation matrix: {e}")

        # Include parameters for physical validation
        params = json_data.get('parameters', {})

        return {
            'n_data_points': fit_stats.get('n_data_points', 0),
            'n_variables': fit_stats.get('n_variables', 4),
            'reduced_chi_square': fit_stats.get('reduced_chi_square', 0),
            'rms_real': residuals.get('real_part', {}).get('rms', 0),
            'rms_imag': residuals.get('imaginary_part', {}).get('rms', 0),
            'mean_real': residuals.get('real_part', {}).get('mean', 0),
            'mean_imag': residuals.get('imaginary_part', {}).get('mean', 0),
            'aic': json_data.get('information_criteria', {}).get('aic', 0),
            'bic': json_data.get('information_criteria', {}).get('bic', 0),
            'correlations': correlations,
            'parameters': params,
            'eps_inf': params.get('eps_inf', 0),
            'n_poles': params.get('n_poles', 1)
        }

    def _validate_report(self, report: Dict[str, Any]) -> None:
        """Validate report data types and values."""
        try:
            n_data = int(report['n_data_points'])
            n_vars = int(report['n_variables'])
            if n_vars <= 0:
                raise ValueError("n_variables must be positive")
            if n_data <= n_vars:
                raise ValueError("n_data_points must exceed n_variables")
            numeric_fields = ['reduced_chi_square', 'rms_real', 'rms_imag', 'mean_real', 'mean_imag']
            for field in numeric_fields:
                val = report.get(field, 0)
                if not isinstance(val, (int, float)) or math.isnan(val):
                    raise ValueError(f"{field} must be a valid number")
        except (TypeError, ValueError, KeyError) as e:
            raise ValueError(f"Invalid report data: {e}")

    def _validate_physical_bounds(self, report: Dict[str, Any]) -> List[str]:
        """Check if values are physically reasonable for Multi-Pole Debye."""
        warnings = []
        if report.get('rms_real', 0) > 1.0:
            warnings.append("RMS real part unusually high - check data quality")
        if report.get('rms_imag', 0) > 0.1:
            warnings.append("RMS imaginary part very high - check loss data quality")
        rcs = report.get('reduced_chi_square', 0)
        if rcs < 1e-6 and rcs > 0:
            warnings.append("Reduced chi-square suspiciously low - possible overfitting")
        elif rcs > 1.0:
            warnings.append("Reduced chi-square > 1 - consider adding more poles")

        # Check epsilon infinity
        eps_inf = report.get('eps_inf', 0)
        if eps_inf < 1.0:
            warnings.append("ε_∞ < 1.0 is unusual for dielectric materials")
        elif eps_inf > 1000:
            warnings.append("ε_∞ > 1000 is unusually high - check units and data")

        # Check number of poles vs data points
        n_poles = report.get('n_poles', 1)
        n_data_points = report.get('n_data_points', 0)
        if n_poles > 0 and n_data_points > 0:
            params_per_pole = 2  # delta_eps and tau for each pole
            total_params = 1 + n_poles * params_per_pole  # eps_inf + poles
            if total_params > n_data_points / 3:
                warnings.append(f"Too many poles ({n_poles}) for data size - risk of overfitting")

        # Check for relaxation time constants in parameters
        params = report.get('parameters', {})
        for i in range(n_poles):
            tau = params.get(f'tau_{i}', None)
            if tau is not None and tau <= 0:
                warnings.append(f"Non-positive τ_{i} detected - unphysical relaxation time")

        return warnings

    def _evaluate_scalar(self, value: float, thresholds: Tuple[float, float, float]) -> Tuple[int, str]:
        """Evaluates metrics where smaller values are better."""
        godly_max, excellent_max, good_max = thresholds
        if value < godly_max:
            return 100, "Godly"
        elif value < excellent_max:
            return 80, "Excellent"
        elif value < good_max:
            return 60, "Good"
        return 30, "Poor"

    def _evaluate_inverse_scalar(self, value: float, thresholds: Tuple[float, float, float]) -> Tuple[int, str]:
        """Evaluates metrics where larger values are better."""
        poor_min, good_min, excellent_min = thresholds
        if value >= excellent_min:
            return 100, "Godly"
        elif value >= good_min:
            return 80, "Excellent"
        elif value >= poor_min:
            return 60, "Good"
        return 30, "Poor"

    def _evaluate_correlation(self, corr_value: float) -> Tuple[int, str, str | None]:
        """Evaluates correlation, returning score, category, and suggestion."""
        if not isinstance(corr_value, (int, float)) or math.isnan(corr_value):
            return 30, "Invalid", "Check correlation calculation"
        abs_corr = abs(corr_value)
        if abs_corr < 0.50:
            return 100, "Low", None
        elif abs_corr < 0.80:
            return 80, "Moderate", None
        elif abs_corr < 0.95:
            return 60, "High", "Consider merging poles or fixing parameters."
        return 30, "Very High", "Poles may be redundant - reduce number of poles."

    def evaluate(self, report: Dict[str, Any]) -> ReportEvaluation:
        """Validates and evaluates a fit report dictionary."""
        required = {
            'n_data_points', 'n_variables', 'reduced_chi_square',
            'rms_real', 'rms_imag', 'mean_real', 'mean_imag', 'correlations'
        }
        missing = required - report.keys()
        if missing:
            raise KeyError(f"Missing required report fields: {missing}")

        self._validate_report(report)
        warnings = self._validate_physical_bounds(report)

        metrics: Dict[str, MetricResult] = {}
        suggestions: List[str] = []

        mean_res = max(abs(report['mean_real']), abs(report['mean_imag']))
        report_vals = dict(report)
        report_vals['mean_residual'] = mean_res

        # Data-points-per-variable
        dpv = report['n_data_points'] / report['n_variables']
        dpv_score, dpv_cat = self._evaluate_inverse_scalar(dpv, (10, 20, 30))
        dpv_sug = "Collect more data or reduce number of poles." if dpv_cat == "Poor" else None
        metrics['dpv'] = MetricResult('dpv', dpv_score, dpv_cat, dpv, dpv_sug)
        if dpv_sug:
            suggestions.append(dpv_sug)

        # Scalar metrics
        for name, (g, e, gd, sug) in self.thresholds.items():
            val = report_vals.get(name, 0)
            sc, cat = self._evaluate_scalar(val, (g, e, gd))
            sugg = sug if cat == "Poor" else None
            metrics[name] = MetricResult(name, sc, cat, val, sugg)
            if sugg:
                suggestions.append(sugg)

        # Correlation
        corrs = report['correlations']
        if not corrs:
            corr_score, corr_cat, corr_sug = 100, "Low", None
            worst_pair, worst_val = None, 0.0
        else:
            worst_pair, worst_val = max(corrs.items(), key=lambda kv: abs(kv[1]))
            corr_score, corr_cat, corr_sug = self._evaluate_correlation(worst_val)

        corr_result = MetricResult(
            'correlation', corr_score, corr_cat,
            worst_val, corr_sug, details={'pair': worst_pair}
        )
        metrics['correlation'] = corr_result
        if corr_sug:
            suggestions.append(corr_sug)

        # Overall score
        total_weight = sum(self.weights.values())
        overall_score = sum(
            metrics[k].score * self.weights.get(k, 1)
            for k in metrics.keys()
            if k in self.weights
        ) / total_weight

        if overall_score >= 90:
            overall_cat = "Godly"
        elif overall_score >= 75:
            overall_cat = "Excellent"
        elif overall_score >= 60:
            overall_cat = "Good"
        else:
            overall_cat = "Poor"

        overall = MetricResult("overall", round(overall_score, 1), overall_cat, round(overall_score, 1))
        return ReportEvaluation(metrics=metrics, overall=overall, suggestions=suggestions, warnings=warnings)

# Global variables to store data
global_f_ghz = None
global_complex_epsilon = None
global_correlation_matrix = None
global_measured_dk = None
global_measured_df = None
global_n_poles = None
global_scale_real = None
global_scale_imag = None
global_sigma_dk = None
global_sigma_df = None
global_weights_real = None
global_weights_imag = None

def load_data(csv_content):
    global global_f_ghz, global_complex_epsilon, global_sigma_dk, global_sigma_df
    global global_weights_real, global_weights_imag
    try:
        data = pd.read_csv(io.StringIO(csv_content)).dropna()
        f_ghz = data.iloc[:, 0].values
        dk = data.iloc[:, 1].values
        df = data.iloc[:, 2].values
        
        # Check for uncertainty columns (columns 4 and 5)
        if data.shape[1] >= 5:
            # Uncertainties provided
            sigma_dk = data.iloc[:, 3].values
            sigma_df = data.iloc[:, 4].values
            global_sigma_dk = sigma_dk
            global_sigma_df = sigma_df
            
            # Calculate weights as 1/sigma^2 (variance weighting)
            # Avoid division by zero
            global_weights_real = np.where(sigma_dk > 0, 1.0 / sigma_dk**2, 1.0)
            global_weights_imag = np.where(sigma_df > 0, 1.0 / (sigma_df * dk)**2, 1.0)
        else:
            # No uncertainties provided - use default weighting
            global_sigma_dk = None
            global_sigma_df = None
            
            # Weight imaginary part by 1/Dk^2 to balance relative errors
            global_weights_real = np.ones_like(dk)
            global_weights_imag = 1.0 / dk**2  # Weight by 1/Dk^2 for Df
        
        # Normalize weights to have mean = 1 for each component
        global_weights_real = global_weights_real / np.mean(global_weights_real)
        global_weights_imag = global_weights_imag / np.mean(global_weights_imag)
        
        complex_epsilon = dk - 1j * (dk * df)
        global_f_ghz = f_ghz
        global_complex_epsilon = complex_epsilon
        return f_ghz, complex_epsilon
    except Exception as e:
        raise ValueError(f"Failed to parse CSV: {e}")

def quick_single_fit(f_ghz, complex_epsilon, initial_params, n_poles, max_iter=20):
    """Perform a quick fit for BIC calculation with limited iterations."""
    params = Parameters()
    
    # Add epsilon infinity
    dk_data = np.real(complex_epsilon)
    params.add('eps_inf', value=initial_params['eps_inf'], min=1.0, max=dk_data.max())
    
    # Add poles
    for i in range(n_poles):
        params.add(f'delta_eps_{i}',
                  value=initial_params.get(f'delta_eps_{i}', 0.5),
                  min=-10,
                  max=dk_data.max() - 1.0)
        
        params.add(f'tau_{i}',
                  value=initial_params.get(f'tau_{i}', 1e-9),
                  min=1e-15,
                  max=1e-6)
    
    # Add constraints for ordered relaxation times
    for i in range(1, n_poles):
        params.add(f'tau_ratio_{i}', value=2.0, min=1.1, max=100)
        params[f'tau_{i}'].expr = f'tau_{i-1} * tau_ratio_{i}'
    
    # Quick minimization with limited iterations
    minimizer = Minimizer(residual, params, fcn_args=(f_ghz, complex_epsilon, n_poles))
    result = minimizer.minimize(method='leastsq', max_nfev=max_iter)
    
    # Calculate BIC
    residuals = residual(result.params, f_ghz, complex_epsilon, n_poles)
    n_data = len(residuals)
    n_params = n_poles * 2 + 1  # delta_eps and tau for each pole, plus eps_inf
    rss = np.sum(residuals**2)
    
    if n_data > 0 and rss > 0:
        bic = n_params * np.log(n_data) + n_data * np.log(rss / n_data)
    else:
        bic = np.inf
    
    return {'bic': bic, 'params': result.params.valuesdict(), 'rss': rss}

def select_poles_bic(f_ghz, complex_epsilon, max_poles=4):
    """Select optimal number of poles using Bayesian Information Criterion."""
    bic_best, best_n = np.inf, 1
    bic_values = {}
    
    for n in range(1, max_poles + 1):
        try:
            # Get initial parameters for n poles
            initial_params = estimate_initial_parameters(f_ghz, complex_epsilon, n, random_seed=42)
            
            # Perform quick fit
            fit_result = quick_single_fit(f_ghz, complex_epsilon, initial_params, n)
            bic = fit_result['bic']
            bic_values[n] = bic
            
            # Check if this model is significantly better (ΔBIC > 2)
            if bic < bic_best - 2:
                bic_best, best_n = bic, n
                
        except Exception as e:
            logger.warning(f"BIC calculation failed for {n} poles: {e}")
            continue
    
    logger.info(f"BIC values: {bic_values}")
    logger.info(f"Selected {best_n} poles with BIC = {bic_best:.2f}")
    
    return best_n

def detect_poles_second_derivative(f_ghz, complex_epsilon):
    """Detect poles using second derivative of log(ε″)."""
    eps_imag = -np.imag(complex_epsilon)
    
    # Remove zero or negative values for log
    valid_mask = eps_imag > 1e-10
    if np.sum(valid_mask) < 10:
        return 1
    
    f_valid = f_ghz[valid_mask]
    eps_valid = eps_imag[valid_mask]
    
    # Take log and smooth
    log_eps = np.log(eps_valid)
    
    # Calculate derivatives using finite differences
    if len(log_eps) < 5:
        return 1
    
    # First derivative
    d1_log_eps = np.gradient(log_eps, f_valid)
    
    # Second derivative
    d2_log_eps = np.gradient(d1_log_eps, f_valid)
    
    # Find zero crossings of second derivative (inflection points)
    zero_crossings = []
    for i in range(1, len(d2_log_eps) - 1):
        if d2_log_eps[i-1] * d2_log_eps[i+1] < 0:  # Sign change
            zero_crossings.append(i)
    
    # Filter out closely spaced crossings
    if len(zero_crossings) > 1:
        filtered_crossings = [zero_crossings[0]]
        for zc in zero_crossings[1:]:
            if zc - filtered_crossings[-1] > len(d2_log_eps) // 10:  # Minimum separation
                filtered_crossings.append(zc)
        zero_crossings = filtered_crossings
    
    # Number of poles approximately equals number of inflection points
    n_poles = max(1, min(len(zero_crossings), 4))
    
    return n_poles

def detect_number_of_poles(f_ghz, complex_epsilon):
    """Auto-detect the number of Debye poles using multiple methods."""
    eps_imag = -np.imag(complex_epsilon)
    
    if len(eps_imag) < 5:
        return 1, "insufficient_data"
    
    detection_method = None
    
    # Method 1: BIC-based selection (most robust)
    try:
        n_poles_bic = select_poles_bic(f_ghz, complex_epsilon, max_poles=4)
    except Exception as e:
        logger.warning(f"BIC method failed: {e}")
        n_poles_bic = None
    
    # Method 2: Second derivative of log(ε″)
    try:
        n_poles_d2 = detect_poles_second_derivative(f_ghz, complex_epsilon)
    except Exception as e:
        logger.warning(f"Second derivative method failed: {e}")
        n_poles_d2 = None
    
    # Method 3: Peak finding (fallback, improved)
    try:
        # Smooth the data with adaptive window
        window = min(7, len(eps_imag) // 4)
        if window >= 3:
            smoothed = np.convolve(eps_imag, np.ones(window)/window, mode='valid')
        else:
            smoothed = eps_imag
        
        # Dynamic prominence based on noise level
        noise_level = np.std(np.diff(smoothed))
        prominence = max(0.02 * np.max(smoothed), 3 * noise_level)
        
        peaks, properties = find_peaks(smoothed, prominence=prominence, distance=len(smoothed)//10)
        n_poles_peaks = len(peaks)
        
        if n_poles_peaks == 0:
            n_poles_peaks = 1
        elif n_poles_peaks > 4:
            n_poles_peaks = 3
    except Exception as e:
        logger.warning(f"Peak finding method failed: {e}")
        n_poles_peaks = 1
    
    # Combine results with preference for BIC
    if n_poles_bic is not None:
        n_poles = n_poles_bic
        detection_method = "BIC"
        logger.info(f"Using BIC method: {n_poles} poles")
    elif n_poles_d2 is not None:
        n_poles = n_poles_d2
        detection_method = "second_derivative"
        logger.info(f"Using second derivative method: {n_poles} poles")
    else:
        n_poles = n_poles_peaks
        detection_method = "peak_finding"
        logger.info(f"Using peak finding method: {n_poles} poles")
    
    return n_poles, detection_method

def estimate_tau_cole_cole(f_ghz, complex_epsilon, eps_inf=None, eps_s=None):
    """Estimate relaxation time using Cole-Cole transformation."""
    dk = np.real(complex_epsilon)
    
    # Estimate eps_inf and eps_s if not provided
    if eps_inf is None:
        # Use high-frequency limit (last 10% of data)
        high_freq_idx = int(0.9 * len(dk))
        eps_inf = np.mean(dk[high_freq_idx:]) if high_freq_idx < len(dk) else dk[-1]
    
    if eps_s is None:
        # Use low-frequency limit (first 10% of data)
        low_freq_idx = int(0.1 * len(dk))
        eps_s = np.mean(dk[:low_freq_idx]) if low_freq_idx > 0 else dk[0]
    
    # Avoid division by zero
    if abs(eps_s - eps_inf) < 1e-6:
        return None
    
    # Cole-Cole transformation
    # For Debye model: (ε - ε∞)/(εs - ε∞) = 1/(1 + jωτ)
    # Phase angle φ = arctan(ωτ), so φ = π/4 when ωτ = 1
    try:
        # Calculate normalized complex permittivity
        eps_norm = (complex_epsilon - eps_inf) / (eps_s - eps_inf)
        
        # Calculate phase angle
        phi = np.angle(eps_norm)
        
        # Find frequency where phase is closest to -π/4 (for Debye relaxation)
        target_phase = -np.pi / 4
        idx_min = np.argmin(np.abs(phi - target_phase))
        
        # Estimate tau from this frequency
        f_relax = f_ghz[idx_min]
        tau_est = 1 / (2 * np.pi * f_relax * 1e9)
        
        return tau_est
    except Exception as e:
        logger.warning(f"Cole-Cole tau estimation failed: {e}")
        return None

def find_loss_peaks_advanced(f_ghz, complex_epsilon, n_expected=None):
    """Find loss peaks with improved peak detection for overlapping relaxations."""
    eps_imag = -np.imag(complex_epsilon)
    
    if len(eps_imag) < 3:
        return []
    
    # Apply mild smoothing to reduce noise
    window = min(5, len(eps_imag) // 5)
    if window >= 3:
        eps_smooth = np.convolve(eps_imag, np.ones(window)/window, mode='same')
    else:
        eps_smooth = eps_imag
    
    # Find all local maxima
    peaks = []
    for i in range(1, len(eps_smooth) - 1):
        if eps_smooth[i] > eps_smooth[i-1] and eps_smooth[i] > eps_smooth[i+1]:
            peaks.append(i)
    
    if not peaks:
        # If no peaks found, use maximum
        peaks = [np.argmax(eps_smooth)]
    
    # Sort peaks by prominence
    peak_values = [eps_smooth[p] for p in peaks]
    sorted_indices = np.argsort(peak_values)[::-1]
    peaks = [peaks[i] for i in sorted_indices]
    
    # If we expect a certain number of peaks, try to find them
    if n_expected and len(peaks) < n_expected:
        # Look for shoulders or inflection points
        d2_eps = np.gradient(np.gradient(eps_smooth))
        for i in range(1, len(d2_eps) - 1):
            if d2_eps[i-1] > 0 and d2_eps[i+1] < 0:  # Inflection point
                if i not in peaks:
                    peaks.append(i)
    
    # Convert to frequencies
    peak_frequencies = [f_ghz[p] for p in peaks[:n_expected] if p < len(f_ghz)]
    
    return peak_frequencies

def estimate_initial_parameters(f_ghz, complex_epsilon, n_poles=None, random_seed=None):
    """Estimate initial parameters for Multi-Pole Debye model with improved tau estimation."""
    dk = np.real(complex_epsilon)
    df = -np.imag(complex_epsilon) / np.real(complex_epsilon)
    
    # Set random seed for reproducibility
    if random_seed is not None:
        np.random.seed(random_seed)

    # Auto-detect poles if not specified
    if n_poles is None or n_poles == 'auto':
        n_poles, _ = detect_number_of_poles(f_ghz, complex_epsilon)

    # Estimate eps_inf and eps_s more robustly
    # Use percentiles to be less sensitive to outliers
    high_freq_idx = int(0.8 * len(dk))
    low_freq_idx = int(0.2 * len(dk))
    
    eps_inf = np.median(dk[high_freq_idx:]) if high_freq_idx < len(dk) else dk[-1]
    eps_s = np.median(dk[:low_freq_idx]) if low_freq_idx > 0 else dk[0]
    
    # Ensure physical constraints
    eps_inf = max(1.0, eps_inf)
    eps_s = max(eps_inf + 0.1, eps_s)  # eps_s should be > eps_inf
    
    total_delta_eps = eps_s - eps_inf

    # Initialize parameters dictionary
    params = {'eps_inf': eps_inf, 'n_poles': n_poles}

    if n_poles == 1:
        # Single pole case - use Cole-Cole transformation
        tau_cc = estimate_tau_cole_cole(f_ghz, complex_epsilon, eps_inf, eps_s)
        
        if tau_cc is not None:
            params['tau_0'] = tau_cc
        else:
            # Fallback to maximum loss method
            max_loss_idx = np.argmax(-np.imag(complex_epsilon))
            f_max = f_ghz[max_loss_idx]
            params['tau_0'] = 1 / (2 * np.pi * f_max * 1e9)
        
        params['delta_eps_0'] = total_delta_eps
        
    else:
        # Multiple poles case
        # Try to find actual peak frequencies
        peak_freqs = find_loss_peaks_advanced(f_ghz, complex_epsilon, n_poles)
        
        if len(peak_freqs) >= n_poles:
            # Use detected peaks for tau values
            for i in range(n_poles):
                params[f'tau_{i}'] = 1 / (2 * np.pi * peak_freqs[i] * 1e9)
                params[f'delta_eps_{i}'] = total_delta_eps / n_poles
        else:
            # Fallback to logarithmic spacing, but biased toward detected peaks
            f_min = f_ghz[0] if len(f_ghz) > 0 else 0.1
            f_max = f_ghz[-1] if len(f_ghz) > 0 else 100.0
            
            if peak_freqs:
                # Use detected peaks as anchors
                f_min = min(f_min, min(peak_freqs) * 0.3)
                f_max = max(f_max, max(peak_freqs) * 3.0)
            
            # Create tau values with some randomization to avoid local minima
            log_f_min = np.log10(f_min)
            log_f_max = np.log10(f_max)
            
            # Add small random perturbations to help optimizer
            log_f_poles = np.linspace(log_f_min, log_f_max, n_poles)
            log_f_poles += np.random.uniform(-0.1, 0.1, n_poles) * (log_f_max - log_f_min) / n_poles
            f_poles = 10**log_f_poles
            
            # Assign parameters
            for i in range(n_poles):
                params[f'tau_{i}'] = 1 / (2 * np.pi * f_poles[i] * 1e9)
                
                # Vary delta_eps slightly to help optimizer
                variation = 1.0 + np.random.uniform(-0.2, 0.2)
                params[f'delta_eps_{i}'] = (total_delta_eps / n_poles) * variation
        
        # Ensure sum of delta_eps equals total
        sum_delta = sum(params[f'delta_eps_{i}'] for i in range(n_poles))
        if sum_delta > 0:
            for i in range(n_poles):
                params[f'delta_eps_{i}'] *= total_delta_eps / sum_delta

    return params

def calculate_model_from_params(params_dict):
    """Calculate Multi-Pole Debye model from parameters dictionary."""
    global global_f_ghz
    if global_f_ghz is None:
        return json.dumps({"error": "No data loaded"})

    f_ghz = global_f_ghz
    omega = 2 * np.pi * f_ghz * 1e9

    eps_inf = params_dict.get('eps_inf', 1.0)
    n_poles = params_dict.get('n_poles', 1)

    # Start with epsilon infinity
    complex_eps = np.full_like(f_ghz, eps_inf, dtype=complex)

    # Add each Debye pole
    for i in range(n_poles):
        delta_eps = params_dict.get(f'delta_eps_{i}', 0)
        tau = params_dict.get(f'tau_{i}', 1e-12)

        # Debye relaxation: Δε / (1 + jωτ)
        denominator = 1 + 1j * omega * tau
        complex_eps += delta_eps / denominator

    eps_prime = np.real(complex_eps)
    eps_double_prime = -np.imag(complex_eps)

    return json.dumps({
        "eps_prime": eps_prime.tolist(),
        "eps_double_prime": eps_double_prime.tolist()
    })

def calculate_model(params_dict, f_ghz):
    """Calculate Multi-Pole Debye model for given parameters and frequencies."""
    omega = 2 * np.pi * f_ghz * 1e9

    eps_inf = params_dict.get('eps_inf', 1.0)
    n_poles = params_dict.get('n_poles', 1)

    # Start with epsilon infinity
    complex_eps = np.full_like(f_ghz, eps_inf, dtype=complex)

    # Add each Debye pole
    for i in range(n_poles):
        delta_eps = params_dict.get(f'delta_eps_{i}', 0)
        tau = params_dict.get(f'tau_{i}', 1e-12)

        # Debye relaxation: Δε / (1 + jωτ)
        denominator = 1 + 1j * omega * tau
        complex_eps += delta_eps / denominator

    return complex_eps

def residual(params, f_ghz, complex_epsilon_data, n_poles):
    """Residual function for Multi-Pole Debye model with heteroscedastic weighting."""
    global global_scale_real, global_scale_imag, global_weights_real, global_weights_imag
    
    p_dict = params.valuesdict()
    p_dict['n_poles'] = n_poles
    model_epsilon = calculate_model(p_dict, f_ghz)
    
    # Calculate and store scaling factors on first call
    if global_scale_real is None:
        global_scale_real = np.max(np.abs(np.real(complex_epsilon_data))) or 1.0
        global_scale_imag = np.max(np.abs(np.imag(complex_epsilon_data))) or 1.0
    
    # Calculate unweighted residuals
    real_residual = (np.real(model_epsilon) - np.real(complex_epsilon_data))
    imag_residual = (np.imag(model_epsilon) - np.imag(complex_epsilon_data))
    
    # Apply scaling
    real_residual_scaled = real_residual / global_scale_real
    imag_residual_scaled = imag_residual / global_scale_imag
    
    # Apply weights if available
    if global_weights_real is not None and global_weights_imag is not None:
        real_residual_weighted = real_residual_scaled * np.sqrt(global_weights_real)
        imag_residual_weighted = imag_residual_scaled * np.sqrt(global_weights_imag)
    else:
        real_residual_weighted = real_residual_scaled
        imag_residual_weighted = imag_residual_scaled

    return np.concatenate([real_residual_weighted, imag_residual_weighted])

def calculate_jacobian(params_dict, f_ghz, n_poles, rel_step=1e-6, abs_step=1e-12):
    """Calculate Jacobian matrix using finite differences with proper scaling."""
    global global_scale_real, global_scale_imag, global_weights_real, global_weights_imag
    
    param_names = ['eps_inf']
    for i in range(n_poles):
        param_names.extend([f'delta_eps_{i}', f'tau_{i}'])

    n_params = len(param_names)
    n_data = len(f_ghz) * 2  # real and imag parts

    jacobian = np.zeros((n_data, n_params))

    # Base model
    params_dict['n_poles'] = n_poles
    base_model = calculate_model(params_dict, f_ghz)

    # Use global scaling factors for consistency
    scale_real = global_scale_real if global_scale_real is not None else (np.max(np.abs(np.real(base_model))) or 1.0)
    scale_imag = global_scale_imag if global_scale_imag is not None else (np.max(np.abs(np.imag(base_model))) or 1.0)

    # Apply scaling and weights
    real_base = np.real(base_model) / scale_real
    imag_base = np.imag(base_model) / scale_imag
    
    if global_weights_real is not None and global_weights_imag is not None:
        real_base *= np.sqrt(global_weights_real)
        imag_base *= np.sqrt(global_weights_imag)
    
    base_residual = np.concatenate([real_base, imag_base])

    # Calculate derivatives
    for i, param_name in enumerate(param_names):
        if param_name in params_dict:
            # Use relative step
            step = rel_step * abs(params_dict[param_name]) + abs_step
            params_plus = params_dict.copy()
            params_plus[param_name] += step

            model_plus = calculate_model(params_plus, f_ghz)
            real_plus = np.real(model_plus) / scale_real
            imag_plus = np.imag(model_plus) / scale_imag
            
            if global_weights_real is not None and global_weights_imag is not None:
                real_plus *= np.sqrt(global_weights_real)
                imag_plus *= np.sqrt(global_weights_imag)
            
            residual_plus = np.concatenate([real_plus, imag_plus])

            jacobian[:, i] = (residual_plus - base_residual) / step

    return jacobian

def calculate_correlation_matrix(params_dict, f_ghz, complex_epsilon_data, n_poles):
    """Calculate correlation matrix from Jacobian."""
    try:
        # Calculate Jacobian
        J = calculate_jacobian(params_dict, f_ghz, n_poles)

        # Calculate covariance matrix: (J^T J)^-1
        JTJ = np.dot(J.T, J)

        # Add small regularization to ensure positive definite
        JTJ += np.eye(JTJ.shape[0]) * 1e-10

        # Calculate covariance
        cov_matrix = np.linalg.inv(JTJ)

        # Convert to correlation matrix
        std_devs = np.sqrt(np.diag(cov_matrix))
        corr_matrix = np.zeros_like(cov_matrix)

        for i in range(len(std_devs)):
            for j in range(len(std_devs)):
                if std_devs[i] > 0 and std_devs[j] > 0:
                    corr_matrix[i, j] = cov_matrix[i, j] / (std_devs[i] * std_devs[j])
                else:
                    corr_matrix[i, j] = 0

        return corr_matrix
    except:
        return None

def format_correlation_matrix(corr_matrix, n_poles):
    """Format correlation matrix for display."""
    if corr_matrix is None:
        return "Unable to calculate correlation matrix"

    param_names = ['eps_inf']
    for i in range(n_poles):
        param_names.extend([f'delta_eps_{i}', f'tau_{i}'])

    result = "Correlations:\\n"

    try:
        for i, param1 in enumerate(param_names):
            for j, param2 in enumerate(param_names):
                if j > i:  # Only show upper triangle
                    if i < len(corr_matrix) and j < len(corr_matrix[0]):
                        correlation = corr_matrix[i, j]
                        if abs(correlation) > 0.1:  # Only show significant correlations
                            result += f"    ({param1}, {param2}) = {correlation:+.4f}\\n"
    except (IndexError, TypeError) as e:
        result += f"    Error accessing correlation matrix: {e}\\n"

    return result

def create_updated_report(params_dict):
    """Create an updated report with current parameters."""
    global global_f_ghz, global_complex_epsilon, global_n_poles
    global global_scale_real, global_scale_imag, global_weights_real, global_weights_imag
    
    if global_f_ghz is None:
        return json.dumps({"error": "No data loaded"})

    n_poles = params_dict.get('n_poles', global_n_poles or 1)
    params_dict['n_poles'] = n_poles
    model_epsilon = calculate_model(params_dict, global_f_ghz)

    real_residuals = np.real(model_epsilon) - np.real(global_complex_epsilon)
    imag_residuals = np.imag(model_epsilon) - np.imag(global_complex_epsilon)

    # Use global scaling factors for consistency with optimization
    scale_real = global_scale_real if global_scale_real is not None else (np.max(np.abs(np.real(global_complex_epsilon))) or 1.0)
    scale_imag = global_scale_imag if global_scale_imag is not None else (np.max(np.abs(np.imag(global_complex_epsilon))) or 1.0)

    scaled_real_residuals = real_residuals / scale_real
    scaled_imag_residuals = imag_residuals / scale_imag
    
    # Apply weights if available
    if global_weights_real is not None and global_weights_imag is not None:
        weighted_real_residuals = scaled_real_residuals * np.sqrt(global_weights_real)
        weighted_imag_residuals = scaled_imag_residuals * np.sqrt(global_weights_imag)
    else:
        weighted_real_residuals = scaled_real_residuals
        weighted_imag_residuals = scaled_imag_residuals

    n_dat = len(real_residuals) + len(imag_residuals)
    n_var = 1 + 2 * n_poles  # eps_inf + (delta_eps, tau) for each pole
    chi_sqr = np.sum(weighted_real_residuals**2) + np.sum(weighted_imag_residuals**2)
    rss = chi_sqr
    red_chi_sqr = rss / (n_dat - n_var) if (n_dat - n_var) > 0 else 0

    # Information criteria using weighted RSS
    aic = 2 * n_var + n_dat * np.log(rss / n_dat) if n_dat > 0 else 0
    bic = n_var * np.log(n_dat) + n_dat * np.log(rss / n_dat) if n_dat > 0 else 0

    # Calculate correlation matrix for current parameters
    corr_matrix = calculate_correlation_matrix(params_dict, global_f_ghz, global_complex_epsilon, n_poles)
    corr_text = format_correlation_matrix(corr_matrix, n_poles)

    # Create JSON data structure
    json_data = {
        "model": "Multi-Pole Debye",
        "timestamp": datetime.now().isoformat(),
        "parameters": params_dict,
        "fit_statistics": {
            "n_data_points": n_dat,
            "n_variables": n_var,
            "chi_square": chi_sqr,
            "reduced_chi_square": red_chi_sqr
        },
        "information_criteria": {
            "aic": aic,
            "bic": bic
        },
        "residual_analysis": {
            "real_part": {
                "mean": float(np.mean(real_residuals)),
                "std_dev": float(np.std(real_residuals)),
                "rms": float(np.sqrt(np.mean(real_residuals**2)))
            },
            "imaginary_part": {
                "mean": float(np.mean(imag_residuals)),
                "std_dev": float(np.std(imag_residuals)),
                "rms": float(np.sqrt(np.mean(imag_residuals**2)))
            }
        },
        "correlation_matrix": corr_matrix.tolist() if corr_matrix is not None else None
    }

    # Format poles information
    poles_info = ""
    for i in range(n_poles):
        delta_eps = params_dict.get(f'delta_eps_{i}', 0)
        tau = params_dict.get(f'tau_{i}', 0)
        f_relax = 1 / (2 * np.pi * tau) / 1e9 if tau > 0 else 0
        poles_info += f"    Pole {i+1}:\\n"
        poles_info += f"        Δε_{i} = {delta_eps:.4f}\\n"
        poles_info += f"        τ_{i}  = {tau:.4e} s\\n"
        poles_info += f"        f_relax = {f_relax:.4f} GHz\\n"

    report = f"""Multi-Pole Debye Fit Report
{'=' * 50}
Date: {datetime.now()}

Model and Parameters
--------------------------------------------------
ε*(ω) = ε_∞ + Σ[Δε_i / (1 + jωτ_i)]

Number of poles: {n_poles}

Using current values (manual):
    eps_inf = {params_dict.get('eps_inf', 0):.4f}

{poles_info}

Fit Statistics
    # data points = {n_dat}
    # variables   = {n_var}
    chi-square    = {chi_sqr:.4f}
    reduced chi-square = {red_chi_sqr:.4f}
    AIC              = {aic:.4f}
    BIC              = {bic:.4f}

Residual Analysis
    Real Part (Dk):
        Mean: {np.mean(real_residuals):.4f}
        Std Dev: {np.std(real_residuals):.4f}
        RMS: {np.sqrt(np.mean(real_residuals**2)):.4f}
    Imaginary Part (Loss Factor):
        Mean: {np.mean(imag_residuals):.4f}
        Std Dev: {np.std(imag_residuals):.4f}
        RMS: {np.sqrt(np.mean(imag_residuals**2)):.4f}

{corr_text}
"""
    return json.dumps({"report": report, "json_data": json_data})

def create_plotly_plot(f_ghz, measured_eps, fitted_eps):
    fig = make_subplots(rows=2, cols=1, subplot_titles=('Real Permittivity', 'Loss Tangent'))
    fig.add_trace(go.Scatter(x=f_ghz, y=np.real(measured_eps), mode='markers', name='Measured Dk', marker=dict(color='black')), row=1, col=1)
    fig.add_trace(go.Scatter(x=f_ghz, y=np.real(fitted_eps), mode='lines', name='Fitted Dk', line=dict(color='red')), row=1, col=1)
    measured_df = -np.imag(measured_eps) / np.real(measured_eps)
    fitted_df = -np.imag(fitted_eps) / np.real(fitted_eps)
    fig.add_trace(go.Scatter(x=f_ghz, y=measured_df, mode='markers', name='Measured Df', marker=dict(color='black'), showlegend=False), row=2, col=1)
    fig.add_trace(go.Scatter(x=f_ghz, y=fitted_df, mode='lines', name='Fitted Df', line=dict(color='red'), showlegend=False), row=2, col=1)
    fig.update_xaxes(title_text="Frequency (GHz)", row=1, col=1)
    fig.update_yaxes(title_text="Dielectric Constant (Dk)", row=1, col=1)
    fig.update_xaxes(title_text="Frequency (GHz)", row=2, col=1)
    fig.update_yaxes(title_text="Dissipation Factor (Df)", row=2, col=1)
    fig.update_layout(height=600, margin=dict(l=20, r=20, t=40, b=20), template="plotly_white", legend=dict(yanchor="top", y=0.99, xanchor="right", x=0.99))
    return pio.to_json(fig)

def evaluate_current_fit(params_dict):
    """Evaluate the current fit quality and return evaluation results."""
    global global_f_ghz, global_complex_epsilon, global_n_poles
    global global_scale_real, global_scale_imag, global_weights_real, global_weights_imag
    
    if global_f_ghz is None:
        return json.dumps({"error": "No data loaded"})

    n_poles = params_dict.get('n_poles', global_n_poles or 1)
    params_dict['n_poles'] = n_poles
    model_epsilon = calculate_model(params_dict, global_f_ghz)

    real_residuals = np.real(model_epsilon) - np.real(global_complex_epsilon)
    imag_residuals = np.imag(model_epsilon) - np.imag(global_complex_epsilon)
    
    # Use global scaling factors for consistency
    scale_real = global_scale_real if global_scale_real is not None else (np.max(np.abs(np.real(global_complex_epsilon))) or 1.0)
    scale_imag = global_scale_imag if global_scale_imag is not None else (np.max(np.abs(np.imag(global_complex_epsilon))) or 1.0)
    
    scaled_real_residuals = real_residuals / scale_real
    scaled_imag_residuals = imag_residuals / scale_imag
    
    # Apply weights if available
    if global_weights_real is not None and global_weights_imag is not None:
        weighted_real_residuals = scaled_real_residuals * np.sqrt(global_weights_real)
        weighted_imag_residuals = scaled_imag_residuals * np.sqrt(global_weights_imag)
    else:
        weighted_real_residuals = scaled_real_residuals
        weighted_imag_residuals = scaled_imag_residuals

    n_dat = len(real_residuals) + len(imag_residuals)
    n_var = 1 + 2 * n_poles
    chi_sqr = np.sum(weighted_real_residuals**2) + np.sum(weighted_imag_residuals**2)
    red_chi_sqr = chi_sqr / (n_dat - n_var) if (n_dat - n_var) > 0 else 0

    # Calculate correlation matrix
    corr_matrix = calculate_correlation_matrix(params_dict, global_f_ghz, global_complex_epsilon, n_poles)

    # Create JSON report format
    json_report = {
        "model": "Multi-Pole Debye",
        "timestamp": datetime.now().isoformat(),
        "parameters": params_dict,
        "fit_statistics": {
            "n_data_points": n_dat,
            "n_variables": n_var,
            "chi_square": chi_sqr,
            "reduced_chi_square": red_chi_sqr
        },
        "residual_analysis": {
            "real_part": {
                "mean": float(np.mean(real_residuals)),
                "std_dev": float(np.std(real_residuals)),
                "rms": float(np.sqrt(np.mean(real_residuals**2)))
            },
            "imaginary_part": {
                "mean": float(np.mean(imag_residuals)),
                "std_dev": float(np.std(imag_residuals)),
                "rms": float(np.sqrt(np.mean(imag_residuals**2)))
            }
        },
        "correlation_matrix": corr_matrix.tolist() if corr_matrix is not None else None
    }

    # Evaluate the fit
    try:
        evaluator = FitEvaluator()
        report_data = FitEvaluator.from_json_report(json_report)
        evaluation = evaluator.evaluate(report_data)
        json_report['evaluation'] = evaluation.to_dict()
    except Exception as e:
        logger.warning(f"Could not evaluate fit: {e}")
        json_report['evaluation'] = None

    return json.dumps(json_report)

def create_downloadable_plot(params_dict):
    global global_f_ghz, global_complex_epsilon, global_n_poles
    if global_f_ghz is None:
        return None

    n_poles = params_dict.get('n_poles', global_n_poles or 1)
    params_dict['n_poles'] = n_poles
    fitted_epsilon = calculate_model(params_dict, global_f_ghz)

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6))

    ax1.plot(global_f_ghz, np.real(global_complex_epsilon), 'ko', label='Measured')
    ax1.plot(global_f_ghz, np.real(fitted_epsilon), 'r-', lw=2, label='Fitted')
    ax1.set_xlabel('Frequency (GHz)')
    ax1.set_ylabel('Dielectric Constant (Dk)')
    ax1.set_title('Real Permittivity')
    ax1.legend()
    ax1.grid(True, alpha=0.5)

    measured_df = -np.imag(global_complex_epsilon) / np.real(global_complex_epsilon)
    fitted_df = -np.imag(fitted_epsilon) / np.real(fitted_epsilon)
    ax2.plot(global_f_ghz, measured_df, 'ko', label='Measured')
    ax2.plot(global_f_ghz, fitted_df, 'r-', lw=2, label='Fitted')
    ax2.set_xlabel('Frequency (GHz)')
    ax2.set_ylabel('Dissipation Factor (Df)')
    ax2.set_title('Loss Tangent')
    ax2.legend()
    ax2.grid(True, alpha=0.5)

    plt.tight_layout()

    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=150)
    plt.close(fig)
    buf.seek(0)
    return buf.getvalue()

def run_analysis(csv_content, n_poles_input, method):
    global global_f_ghz, global_complex_epsilon, global_correlation_matrix
    global global_measured_dk, global_measured_df, global_n_poles
    global global_scale_real, global_scale_imag
    
    # Reset scaling factors for new data
    global_scale_real = None
    global_scale_imag = None

    f_ghz, complex_epsilon_data = load_data(csv_content)

    # Store measured data globally
    global_measured_dk = np.real(complex_epsilon_data).tolist()
    global_measured_df = (-np.imag(complex_epsilon_data) / np.real(complex_epsilon_data)).tolist()

    # Determine number of poles
    detection_method_used = None
    if n_poles_input == 'auto':
        n_poles, detection_method_used = detect_number_of_poles(f_ghz, complex_epsilon_data)
        print(f"Auto-detected {n_poles} pole(s) using {detection_method_used} method")
    else:
        n_poles = int(n_poles_input)
        detection_method_used = "manual"

    global_n_poles = n_poles

    initial_params = estimate_initial_parameters(f_ghz, complex_epsilon_data, n_poles, random_seed=42)
    params = Parameters()

    # Add epsilon infinity
    dk_data = np.real(complex_epsilon_data)
    params.add('eps_inf', value=initial_params['eps_inf'], min=1.0, max=dk_data.max())

    # Add poles
    for i in range(n_poles):
        # Relaxation strength (allow negative for anomalous dispersion)
        params.add(f'delta_eps_{i}',
                  value=initial_params[f'delta_eps_{i}'],
                  min=-10,
                  max=dk_data.max() - 1.0)

        # Relaxation time
        params.add(f'tau_{i}',
                  value=initial_params[f'tau_{i}'],
                  min=1e-15,
                  max=1e-6)

    # Add constraints to order relaxation times (tau_0 < tau_1 < tau_2 ...)
    for i in range(1, n_poles):
        params.add(f'tau_ratio_{i}', value=2.0, min=1.1, max=100)
        params[f'tau_{i}'].expr = f'tau_{i-1} * tau_ratio_{i}'

    minimizer = Minimizer(residual, params, fcn_args=(f_ghz, complex_epsilon_data, n_poles))
    result = minimizer.minimize(method=method)

    fit_params = {p: float(v.value) for p, v in result.params.items() if not p.startswith('tau_ratio')}
    fit_params['n_poles'] = n_poles

    # Calculate AIC and BIC using consistent scaling and weights
    fitted_epsilon = calculate_model(result.params.valuesdict(), f_ghz)
    real_residuals = np.real(fitted_epsilon) - np.real(complex_epsilon_data)
    imag_residuals = np.imag(fitted_epsilon) - np.imag(complex_epsilon_data)

    # Use global scaling factors for consistency
    scale_real = global_scale_real if global_scale_real is not None else (np.max(np.abs(np.real(complex_epsilon_data))) or 1.0)
    scale_imag = global_scale_imag if global_scale_imag is not None else (np.max(np.abs(np.imag(complex_epsilon_data))) or 1.0)

    scaled_real_residuals = real_residuals / scale_real
    scaled_imag_residuals = imag_residuals / scale_imag
    
    # Apply weights if available
    if global_weights_real is not None and global_weights_imag is not None:
        weighted_real_residuals = scaled_real_residuals * np.sqrt(global_weights_real)
        weighted_imag_residuals = scaled_imag_residuals * np.sqrt(global_weights_imag)
    else:
        weighted_real_residuals = scaled_real_residuals
        weighted_imag_residuals = scaled_imag_residuals

    n_dat = len(real_residuals) + len(imag_residuals)
    n_var = 1 + 2 * n_poles
    rss = np.sum(weighted_real_residuals**2) + np.sum(weighted_imag_residuals**2)
    aic = 2 * n_var + n_dat * np.log(rss / n_dat) if n_dat > 0 else 0
    bic = n_var * np.log(n_dat) + n_dat * np.log(rss / n_dat) if n_dat > 0 else 0

    # Extract correlation matrix from fit result
    correlations_str = ""
    if hasattr(result, 'var_names') and hasattr(result, 'covar') and result.covar is not None:
        global_correlation_matrix = result.covar
        correlations_str = "\\nCorrelations (from optimization):\\n"
        for i, name1 in enumerate(result.var_names):
            for j, name2 in enumerate(result.var_names):
                if j > i and not ('tau_ratio' in name1 or 'tau_ratio' in name2):
                    try:
                        corr_val = result.covar[i, j] / np.sqrt(result.covar[i, i] * result.covar[j, j])
                        if abs(corr_val) > 0.1:
                            correlations_str += f"    ({name1}, {name2}) = {corr_val:+.4f}\\n"
                    except:
                        pass

    # Generate standard LMFit table
    report_content = fit_report(result).replace('[[', '').replace(']]', '')

    # Format poles information
    poles_info = ""
    for i in range(n_poles):
        delta_eps = fit_params[f'delta_eps_{i}']
        tau = fit_params[f'tau_{i}']
        f_relax = 1 / (2 * np.pi * tau) / 1e9 if tau > 0 else 0
        poles_info += f"    Pole {i+1}:\\n"
        poles_info += f"        Δε_{i} = {delta_eps:.4f}\\n"
        poles_info += f"        τ_{i}  = {tau:.4e} s\\n"
        poles_info += f"        f_relax = {f_relax:.4f} GHz\\n"

    model_section = f"""Model and Parameters
--------------------------------------------------
ε*(ω) = ε_∞ + Σ[Δε_i / (1 + jωτ_i)]

Number of poles: {n_poles}

Using fitted values:
    eps_inf = {fit_params['eps_inf']:.4f}

{poles_info}

Information Criteria:
    AIC = {aic:.4f}
    BIC = {bic:.4f}
"""

    full_report = f"Multi-Pole Debye Fit Report\\n{'=' * 50}\\nDate: {datetime.now()}\\n\\n{model_section}\\n\\n{report_content}"
    plot_json = create_plotly_plot(f_ghz, complex_epsilon_data, fitted_epsilon)

    return_data = {
        "report": full_report,
        "plot_json": plot_json,
        "f_ghz": f_ghz.tolist(),
        "fitted_params": fit_params,
        "correlations": correlations_str,
        "measured_dk": global_measured_dk,
        "measured_df": global_measured_df,
        "n_poles": n_poles,
        "detection_method": detection_method_used
    }
    return json.dumps(return_data)
`;

        async function main() {
            setLoadingState(true, 'Initializing Environment...');
            try {
                pyodide = await loadPyodide({
                    indexURL: "https://cdn.jsdelivr.net/pyodide/v0.24.1/full/"
                });
                setLoadingState(true, 'Loading Python Packages...');
                await pyodide.loadPackage(['numpy', 'pandas', 'micropip', 'matplotlib', 'scipy']);
                const micropip = pyodide.pyimport('micropip');
                setLoadingState(true, 'Installing lmfit & plotly...');
                await micropip.install(['lmfit', 'plotly']);
                isPyodideReady = true;
                await pyodide.runPythonAsync(pythonScript);
                setLoadingState(false);
            } catch (err) {
                isPyodideReady = false;
                showError(`Failed to initialize Python environment: ${err}`);
                setLoadingState(false);
            }
        }

        function setLoadingState(isLoading, message = '') {
            statusMessage.textContent = message;
            statusDiv.style.display = isLoading ? 'flex' : 'none';
            runButton.disabled = isLoading;
            runButton.classList.toggle('btn-disabled', isLoading);
            if (!isLoading) updateButtonState();
        }

        function showError(message) {
            errorMessage.textContent = message;
            errorBox.classList.remove('hidden');
            outputDiv.classList.add('hidden');
        }

        function hideError() {
            errorBox.classList.add('hidden');
        }

        function updateButtonState() {
            const isReady = isPyodideReady && !!fileContent;
            runButton.disabled = !isReady;
            runButton.classList.toggle('btn-disabled', !isReady);
        }

        function createPoleControls(nPoles, params) {
            poleControlsContainer.innerHTML = '';
            currentPoleControls = {};

            for (let i = 0; i < nPoles; i++) {
                const poleDiv = document.createElement('div');
                poleDiv.className = 'pole-controls';
                poleDiv.innerHTML = `
                    <h4 class="text-sm font-semibold text-gray-700 mb-3">Pole ${i + 1}</h4>
                    <div class="space-y-4">
                        <div>
                            <label for="delta_eps_${i}_slider" class="block text-xs font-medium text-gray-600">Δε<sub>${i}</sub></label>
                            <input type="range" id="delta_eps_${i}_slider" class="mt-1">
                            <input type="number" id="delta_eps_${i}_input" class="mt-1 w-full p-1 border border-gray-300 rounded-md text-sm">
                        </div>
                        <div>
                            <label for="tau_${i}_slider" class="block text-xs font-medium text-gray-600">τ<sub>${i}</sub> (s)</label>
                            <input type="range" id="tau_${i}_slider" class="mt-1" step="any">
                            <input type="number" id="tau_${i}_input" class="mt-1 w-full p-1 border border-gray-300 rounded-md text-sm" step="any">
                        </div>
                    </div>
                `;
                poleControlsContainer.appendChild(poleDiv);

                // Store references and set up controls
                const deltaEpsSlider = document.getElementById(`delta_eps_${i}_slider`);
                const deltaEpsInput = document.getElementById(`delta_eps_${i}_input`);
                const tauSlider = document.getElementById(`tau_${i}_slider`);
                const tauInput = document.getElementById(`tau_${i}_input`);

                // Set up delta_eps controls (allow negative values)
                const deltaEps = params[`delta_eps_${i}`] || 0.5;
                const deltaEpsMin = Math.min(-5, deltaEps * 2);
                const deltaEpsMax = Math.max(5, deltaEps * 2);
                deltaEpsSlider.min = deltaEpsMin;
                deltaEpsSlider.max = deltaEpsMax;
                deltaEpsSlider.step = 0.01;
                deltaEpsSlider.value = deltaEps;
                deltaEpsInput.min = deltaEpsMin;
                deltaEpsInput.max = deltaEpsMax;
                deltaEpsInput.step = 0.01;
                deltaEpsInput.value = deltaEps;

                // Set up tau controls (log scale for slider)
                const tau = params[`tau_${i}`] || 1e-9;
                const logTauMin = -15;  // 10^-15 seconds
                const logTauMax = -6;   // 10^-6 seconds
                const logTau = Math.log10(tau);

                tauSlider.min = logTauMin;
                tauSlider.max = logTauMax;
                tauSlider.step = 0.1;
                tauSlider.value = logTau;

                tauInput.min = 1e-15;
                tauInput.max = 1e-6;
                tauInput.step = 1e-15;
                tauInput.value = tau;

                // Store controls
                currentPoleControls[`delta_eps_${i}`] = {
                    slider: deltaEpsSlider,
                    input: deltaEpsInput
                };
                currentPoleControls[`tau_${i}`] = {
                    slider: tauSlider,
                    input: tauInput,
                    isLog: true
                };

                // Add event listeners
                deltaEpsSlider.addEventListener('input', (e) => {
                    deltaEpsInput.value = e.target.value;
                    updateUIFromControls();
                });

                deltaEpsInput.addEventListener('input', (e) => {
                    deltaEpsSlider.value = e.target.value;
                    updateUIFromControls();
                });

                tauSlider.addEventListener('input', (e) => {
                    const tau = Math.pow(10, parseFloat(e.target.value));
                    tauInput.value = tau.toExponential(2);
                    updateUIFromControls();
                });

                tauInput.addEventListener('input', (e) => {
                    const tau = parseFloat(e.target.value);
                    if (tau > 0) {
                        tauSlider.value = Math.log10(tau);
                        updateUIFromControls();
                    }
                });
            }
        }

        function setupParameterControls(params) {
            const nPoles = params.n_poles || 1;
            currentNPoles = nPoles;

            // Set up epsilon infinity control
            const epsInfSlider = document.getElementById('eps_inf_slider');
            const epsInfInput = document.getElementById('eps_inf_input');

            const epsInf = params.eps_inf || 1.0;
            epsInfSlider.min = 1;
            epsInfSlider.max = Math.max(epsInf * 2, 10);
            epsInfSlider.step = 0.01;
            epsInfSlider.value = epsInf;

            epsInfInput.min = 1;
            epsInfInput.max = Math.max(epsInf * 2, 10);
            epsInfInput.step = 0.01;
            epsInfInput.value = epsInf;

            // Create pole controls
            createPoleControls(nPoles, params);

            // Add event listeners for epsilon infinity
            epsInfSlider.addEventListener('input', (e) => {
                epsInfInput.value = e.target.value;
                updateUIFromControls();
            });

            epsInfInput.addEventListener('input', (e) => {
                epsInfSlider.value = e.target.value;
                updateUIFromControls();
            });
        }

        async function updateUIFromControls() {
            if (!currentData || !pyodide) return;

            const params = {
                eps_inf: parseFloat(document.getElementById('eps_inf_input').value),
                n_poles: currentNPoles
            };

            // Collect pole parameters
            for (let i = 0; i < currentNPoles; i++) {
                params[`delta_eps_${i}`] = parseFloat(document.getElementById(`delta_eps_${i}_input`).value);
                params[`tau_${i}`] = parseFloat(document.getElementById(`tau_${i}_input`).value);
            }

            try {
                // Update Plot
                const modelJson = await pyodide.runPythonAsync(`
                    import json
                    params_dict = ${JSON.stringify(params)}
                    result = calculate_model_from_params(params_dict)
                    result
                `);
                const modelResults = JSON.parse(modelJson);

                if (modelResults.error) return;

                const fittedDk = modelResults.eps_prime;
                const fittedDf = fittedDk.map((dk, i) => modelResults.eps_double_prime[i] / dk);
                Plotly.restyle('plot-output', { y: [fittedDk, fittedDf] }, [1, 3]);

                // Update Report
                const reportJson = await pyodide.runPythonAsync(`
                    params_dict = ${JSON.stringify(params)}
                    create_updated_report(params_dict)
                `);
                const reportData = JSON.parse(reportJson);
                reportOutput.textContent = reportData.report;

                // Update fit quality indicator
                const evaluationJson = await pyodide.runPythonAsync(`
                    params_dict = ${JSON.stringify(params)}
                    evaluate_current_fit(params_dict)
                `);
                const evaluationData = JSON.parse(evaluationJson);

                if (evaluationData.evaluation) {
                    updateFitQualityIndicator(evaluationData.evaluation);
                }

            } catch (err) {
                console.error('Error updating UI:', err);
            }
        }

        function updateFitQualityIndicator(evaluation) {
            const indicator = document.getElementById('fit-quality-indicator');
            const scoreSpan = document.getElementById('fit-quality-score');
            const bar = document.getElementById('fit-quality-bar');
            const warningsDiv = document.getElementById('fit-warnings');
            const warningsContainer = document.getElementById('warnings-container');

            if (!evaluation) {
                indicator.classList.add('hidden');
                return;
            }

            indicator.classList.remove('hidden');
            const score = evaluation.overall_score;
            const category = evaluation.overall_category;

            scoreSpan.textContent = `${score} (${category})`;

            // Update bar width and color
            bar.style.width = `${score}%`;

            if (score >= 90) {
                bar.className = 'h-2 rounded-full transition-all duration-300 bg-green-500';
                indicator.className = 'mb-4 p-3 rounded-lg bg-green-50 border border-green-200';
            } else if (score >= 75) {
                bar.className = 'h-2 rounded-full transition-all duration-300 bg-blue-500';
                indicator.className = 'mb-4 p-3 rounded-lg bg-blue-50 border border-blue-200';
            } else if (score >= 60) {
                bar.className = 'h-2 rounded-full transition-all duration-300 bg-yellow-500';
                indicator.className = 'mb-4 p-3 rounded-lg bg-yellow-50 border border-yellow-200';
            } else {
                bar.className = 'h-2 rounded-full transition-all duration-300 bg-red-500';
                indicator.className = 'mb-4 p-3 rounded-lg bg-red-50 border border-red-200';
            }

            // Display warnings
            if (evaluation.warnings && evaluation.warnings.length > 0) {
                warningsDiv.classList.remove('hidden');
                warningsContainer.innerHTML = '';

                evaluation.warnings.forEach(warning => {
                    const badge = document.createElement('div');
                    badge.className = 'inline-block bg-orange-100 text-orange-800 text-xs px-2 py-1 rounded-full border border-orange-200 mr-1 mb-1';
                    badge.textContent = warning.length > 50 ? warning.substring(0, 50) + '...' : warning;
                    badge.title = warning; // Full text on hover
                    warningsContainer.appendChild(badge);
                });
            } else {
                warningsDiv.classList.add('hidden');
            }
        }

        function resetParameters() {
            if (!currentData || !currentData.fitted_params) return;
            setupParameterControls(currentData.fitted_params);

            const plotData = JSON.parse(currentData.plot_json);
            Plotly.restyle('plot-output', {
                y: [plotData.data[1].y, plotData.data[3].y]
            }, [1, 3]);
            reportOutput.textContent = currentData.report;

            // Update fit quality for reset parameters
            pyodide.runPythonAsync(`
                params_dict = ${JSON.stringify(currentData.fitted_params)}
                evaluate_current_fit(params_dict)
            `).then(evaluationJson => {
                const evaluationData = JSON.parse(evaluationJson);
                if (evaluationData.evaluation) {
                    updateFitQualityIndicator(evaluationData.evaluation);
                }
            });
        }

        async function downloadResults() {
            if (!currentData) return;
            setLoadingState(true, 'Preparing download...');
            try {
                const zip = new JSZip();
                const baseFilename = originalFilename.replace(/\.csv$/i, '');

                // Collect current parameters
                const params = {
                    eps_inf: parseFloat(document.getElementById('eps_inf_input').value),
                    n_poles: currentNPoles
                };

                for (let i = 0; i < currentNPoles; i++) {
                    params[`delta_eps_${i}`] = parseFloat(document.getElementById(`delta_eps_${i}_input`).value);
                    params[`tau_${i}`] = parseFloat(document.getElementById(`tau_${i}_input`).value);
                }

                // 1. Create Fitted Data CSV
                const modelJson = await pyodide.runPythonAsync(`
                    import json
                    params_dict = ${JSON.stringify(params)}
                    result = calculate_model_from_params(params_dict)
                    result
                `);
                const modelResults = JSON.parse(modelJson);

                let csvContent = "Frequency_GHz,fitted_Dk,fitted_Df\n";
                currentData.f_ghz.forEach((f, i) => {
                    const dk = modelResults.eps_prime[i];
                    const df = dk === 0 ? 0 : -modelResults.eps_double_prime[i] / dk;
                    csvContent += `${f},${dk},${df}\n`;
                });
                zip.file(`${baseFilename}_fitted.csv`, csvContent);

                // 2. Add Matplotlib Plot Image
                const imageBytes = await pyodide.runPythonAsync(`
                    params_dict = ${JSON.stringify(params)}
                    plot_bytes = create_downloadable_plot(params_dict)
                    list(plot_bytes) if plot_bytes else []
                `);
                if (imageBytes && imageBytes.length > 0) {
                    const imageData = new Uint8Array(imageBytes);
                    zip.file(`${baseFilename}_plot.png`, imageData);
                }

                // 3. Add Report
                zip.file(`${baseFilename}_report.txt`, reportOutput.textContent);

                // 4. Generate JSON report
                const reportJson = await pyodide.runPythonAsync(`
                    params_dict = ${JSON.stringify(params)}
                    create_updated_report(params_dict)
                `);
                const reportData = JSON.parse(reportJson);

                // Get evaluation
                const evaluationJson = await pyodide.runPythonAsync(`
                    params_dict = ${JSON.stringify(params)}
                    evaluate_current_fit(params_dict)
                `);
                const evaluationData = JSON.parse(evaluationJson);

                // Add additional fields to JSON
                const fullJsonReport = {
                    ...reportData.json_data,
                    input_file: originalFilename,
                    data: {
                        frequency_ghz: currentData.f_ghz,
                        measured: {
                            dk: currentData.measured_dk || [],
                            df: currentData.measured_df || []
                        },
                        fitted: {
                            dk: modelResults.eps_prime,
                            df: modelResults.eps_prime.map((dk, i) => {
                                return dk === 0 ? 0 : -modelResults.eps_double_prime[i] / dk;
                            })
                        }
                    },
                    evaluation: evaluationData.evaluation
                };

                zip.file(`${baseFilename}_report.json`, JSON.stringify(fullJsonReport, null, 2));

                // 5. Add evaluation report
                if (evaluationData.evaluation && evaluationData.evaluation.markdown_table) {
                    zip.file(`${baseFilename}_evaluation.md`, evaluationData.evaluation.markdown_table);
                }

                // Generate and Download Zip
                const content = await zip.generateAsync({ type: "blob" });
                const link = document.createElement("a");
                link.href = URL.createObjectURL(content);
                link.download = `${baseFilename}_multipole_debye_results.zip`;
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);

            } catch(err) {
                showError(`Failed to create download package: ${err}`);
            } finally {
                setLoadingState(false);
            }
        }

        // Set up event listeners
        fileUpload.addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (file) {
                originalFilename = file.name;
                const reader = new FileReader();
                reader.onload = (e) => {
                    fileContent = e.target.result;
                    updateButtonState();
                };
                reader.readAsText(file);
            } else {
                fileContent = null;
                originalFilename = '';
                updateButtonState();
            }
        });

        runButton.addEventListener('click', async () => {
            if (!fileContent || !pyodide) return;
            hideError();
            setLoadingState(true, 'Running analysis...');
            outputDiv.classList.add('hidden');

            try {
                const fitMethod = fitMethodSelect.value;
                const nPoles = nPolesSelect.value;

                // Pass the CSV content through a global variable to avoid escaping issues
                await pyodide.runPythonAsync(`
import json
global_csv_content = ${JSON.stringify(fileContent)}
result_json = run_analysis(global_csv_content, '${nPoles}', '${fitMethod}')
result_json
                `).then(async (resultJson) => {
                    const result = JSON.parse(resultJson);

                    currentData = result;

                    const plotData = JSON.parse(result.plot_json);
                    plotOutput.innerHTML = '';
                    Plotly.newPlot('plot-output', plotData.data, plotData.layout, {responsive: true});

                    currentData.measured_dk = result.measured_dk;
                    currentData.measured_df = result.measured_df;

                    reportOutput.textContent = result.report;
                    setupParameterControls(result.fitted_params);

                    // Show detection method if auto-detected
                    if (result.detection_method && result.detection_method !== 'manual') {
                        const methodNames = {
                            'BIC': 'Bayesian Information Criterion',
                            'second_derivative': 'Second Derivative of log(ε″)',
                            'peak_finding': 'Peak Finding (improved)',
                            'insufficient_data': 'Insufficient Data'
                        };
                        const methodName = methodNames[result.detection_method] || result.detection_method;
                        
                        // Add detection method info to status
                        const infoDiv = document.createElement('div');
                        infoDiv.className = 'mt-4 p-3 bg-blue-50 border border-blue-200 rounded-lg text-sm';
                        infoDiv.innerHTML = `<strong>Auto-detection:</strong> ${result.n_poles} pole(s) detected using ${methodName}`;
                        document.getElementById('controls-panel').insertBefore(infoDiv, document.getElementById('controls-panel').firstChild);
                    }

                    // Show initial fit quality
                    const evaluationJson = await pyodide.runPythonAsync(`
                        params_dict = ${JSON.stringify(result.fitted_params)}
                        evaluate_current_fit(params_dict)
                    `);
                    const evaluationData = JSON.parse(evaluationJson);

                    if (evaluationData.evaluation) {
                        updateFitQualityIndicator(evaluationData.evaluation);
                    }

                    outputDiv.classList.remove('hidden');
                });

            } catch (err) {
                console.error(err);
                showError(`An error occurred during analysis: ${err.message}`);
            } finally {
                setLoadingState(false);
            }
        });

        resetButton.addEventListener('click', resetParameters);
        downloadButton.addEventListener('click', downloadResults);

        // Initialize
        main();
        updateButtonState();
    </script>
</body>
</html>